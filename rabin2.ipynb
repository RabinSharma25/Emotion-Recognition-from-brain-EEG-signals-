{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RabinSharma25/Emotion-Recognition-from-brain-EEG-signals-/blob/master/rabin2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pwwbhMy0pssx"
      },
      "outputs": [],
      "source": [
        "#import the required libraries\n",
        "import os\n",
        "import time\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "#for feature extraction\n",
        "from scipy.signal import welch\n",
        "from scipy.integrate import simps\n",
        "\n",
        "#classifier libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import itertools\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_recall_curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7ZUAXilSp_n9"
      },
      "outputs": [],
      "source": [
        "def read_data(filename):\n",
        "    x = pickle._Unpickler(open(filename, 'rb'))\n",
        "    x.encoding = 'latin1'\n",
        "    p = x.load()\n",
        "    return p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYK5hgFMqFNy",
        "outputId": "356a74d0-2cad-4ae6-a412-f5337fa4a562"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['s01.dat', 's02.dat', 's03.dat', 's04.dat', 's05.dat', 's06.dat', 's07.dat', 's08.dat', 's09.dat', 's10.dat', 's11.dat', 's12.dat', 's13.dat', 's14.dat', 's15.dat', 's16.dat', 's17.dat', 's18.dat', 's19.dat', 's20.dat', 's21.dat', 's22.dat', 's23.dat', 's24.dat', 's25.dat', 's26.dat', 's27.dat', 's28.dat', 's29.dat', 's30.dat', 's31.dat', 's32.dat']\n"
          ]
        }
      ],
      "source": [
        "#creating the file names of the dataset to load it\n",
        "files = []\n",
        "for n in range (1, 33):\n",
        "    s = 's'\n",
        "    if n < 10:\n",
        "        s += '0'\n",
        "    s += str(n)\n",
        "    s+=str(\".dat\")\n",
        "    files.append(s)\n",
        "print(files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ru2cxT3qrtI",
        "outputId": "d75966b2-e84e-4bf8-cd86-607073aab145"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# 32x40 = 1280 trials for 32 participants\n",
        "labels = []\n",
        "data = []\n",
        "drive.mount('/content/drive')\n",
        "for i in files:\n",
        "  filename = \"/content/drive/My Drive/major-project/major-project-dataset/\" + i\n",
        "  trial = read_data(filename)\n",
        "  labels.append(trial['labels'])\n",
        "  data.append(trial['data'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwIUirXzuY_3",
        "outputId": "b0ea6ba5-7bbf-4d2d-cbfd-5c0402b1baa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels:  (32, 40, 4)\n",
            "Data:  (32, 40, 40, 8064)\n"
          ]
        }
      ],
      "source": [
        "# Lets see the shapes of the raw data\n",
        "labels = np.array(labels)\n",
        "data = np.array(data)\n",
        "print(\"Labels: \", labels.shape) # participants x videos x labels\n",
        "print(\"Data: \", data.shape) # participants x videos x channels x data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6JhtYReeudzh"
      },
      "outputs": [],
      "source": [
        "# Re-shape arrays into desired shapes\n",
        "labels = labels.flatten()\n",
        "labels = labels.reshape(1280, 4)\n",
        "\n",
        "data = data.flatten()\n",
        "data = data.reshape(1280, 40, 8064)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pw4kk4WasX14",
        "outputId": "9a0960a5-6a55-4119-e4c8-e9d8a1c321bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels:  (1280, 4)\n",
            "Data:  (1280, 40, 8064)\n"
          ]
        }
      ],
      "source": [
        "# Double-check the new arrays\n",
        "#Here trial = participants x vidoes = 32 x 40 = 1280\n",
        "\n",
        "print(\"Labels: \", labels.shape) # trial x label\n",
        "print(\"Data: \", data.shape) # trial x channel x data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "id": "puNQxQcOx0Gq",
        "outputId": "fd804e45-6447-41fe-dcc6-88a24c09fa1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "printing the labels dataframe\n",
            "\n",
            "         0     1     2     3\n",
            "0     7.71  7.60  6.90  7.83\n",
            "1     8.10  7.31  7.28  8.47\n",
            "2     8.58  7.54  9.00  7.08\n",
            "3     4.94  6.01  6.12  8.06\n",
            "4     6.96  3.92  7.19  6.05\n",
            "...    ...   ...   ...   ...\n",
            "1275  3.91  6.96  5.82  3.12\n",
            "1276  2.81  6.13  6.06  1.04\n",
            "1277  3.05  7.01  5.10  1.10\n",
            "1278  3.99  7.17  4.85  1.00\n",
            "1279  7.15  4.03  9.00  1.88\n",
            "\n",
            "[1280 rows x 4 columns]\n",
            "\n",
            "\n",
            "Describing the labels dataframe\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 0            1            2            3\n",
              "count  1280.000000  1280.000000  1280.000000  1280.000000\n",
              "mean      5.254313     5.156711     5.382750     5.518133\n",
              "std       2.130816     2.020499     2.096321     2.282780\n",
              "min       1.000000     1.000000     1.000000     1.000000\n",
              "25%       3.867500     3.762500     3.932500     3.960000\n",
              "50%       5.040000     5.230000     5.240000     6.050000\n",
              "75%       7.050000     6.950000     7.040000     7.090000\n",
              "max       9.000000     9.000000     9.000000     9.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c79ca5ea-2aea-42d6-9b74-1fc8a6a8a213\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1280.000000</td>\n",
              "      <td>1280.000000</td>\n",
              "      <td>1280.000000</td>\n",
              "      <td>1280.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.254313</td>\n",
              "      <td>5.156711</td>\n",
              "      <td>5.382750</td>\n",
              "      <td>5.518133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.130816</td>\n",
              "      <td>2.020499</td>\n",
              "      <td>2.096321</td>\n",
              "      <td>2.282780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.867500</td>\n",
              "      <td>3.762500</td>\n",
              "      <td>3.932500</td>\n",
              "      <td>3.960000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.040000</td>\n",
              "      <td>5.230000</td>\n",
              "      <td>5.240000</td>\n",
              "      <td>6.050000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7.050000</td>\n",
              "      <td>6.950000</td>\n",
              "      <td>7.040000</td>\n",
              "      <td>7.090000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c79ca5ea-2aea-42d6-9b74-1fc8a6a8a213')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c79ca5ea-2aea-42d6-9b74-1fc8a6a8a213 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c79ca5ea-2aea-42d6-9b74-1fc8a6a8a213');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9c3cdb4b-4684-43be-834c-902e7987d715\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9c3cdb4b-4684-43be-834c-902e7987d715')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9c3cdb4b-4684-43be-834c-902e7987d715 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"labelsDf\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 450.87147400594165,\n        \"min\": 1.0,\n        \"max\": 1280.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          5.2543125,\n          5.04,\n          1280.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 450.88279505775586,\n        \"min\": 1.0,\n        \"max\": 1280.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          5.1567109375,\n          5.23,\n          1280.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 450.85389766830843,\n        \"min\": 1.0,\n        \"max\": 1280.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          5.38275,\n          5.24,\n          1280.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 450.79289858765816,\n        \"min\": 1.0,\n        \"max\": 1280.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          5.5181328125,\n          6.05,\n          1280.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#creating the dataframes for the labels\n",
        "labelsDf = pd.DataFrame(labels)\n",
        "print(\"printing the labels dataframe\\n\")\n",
        "print(labelsDf)\n",
        "print(\"\\n\\nDescribing the labels dataframe\")\n",
        "labelsDf.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SGS2ghM3uYC",
        "outputId": "0f4f7ee8-ce87-4ba5-b302-c9923502baa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 0            1            2            3\n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000\n",
            "mean      5.254313     5.156711     5.382750     5.518133\n",
            "std       2.130816     2.020499     2.096321     2.282780\n",
            "min       1.000000     1.000000     1.000000     1.000000\n",
            "25%       3.867500     3.762500     3.932500     3.960000\n",
            "50%       5.040000     5.230000     5.240000     6.050000\n",
            "75%       7.050000     6.950000     7.040000     7.090000\n",
            "max       9.000000     9.000000     9.000000     9.000000\n"
          ]
        }
      ],
      "source": [
        "#giving names to the label columns\n",
        "df_labels= pd.DataFrame({'valence': labels[:,0], 'arousal': labels[:,1], 'dominance': labels[:,2], 'liking': labels[:,3]})\n",
        "print(labelsDf.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3boVQ1FE4var",
        "outputId": "08f334ad-1a4a-4fa6-8779-0fb36c0222e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      valence  arousal\n",
            "0        7.71     7.60\n",
            "1        8.10     7.31\n",
            "2        8.58     7.54\n",
            "3        4.94     6.01\n",
            "4        6.96     3.92\n",
            "...       ...      ...\n",
            "1275     3.91     6.96\n",
            "1276     2.81     6.13\n",
            "1277     3.05     7.01\n",
            "1278     3.99     7.17\n",
            "1279     7.15     4.03\n",
            "\n",
            "[1280 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "#Dropping the Dominance and Liking columns\n",
        "df_labels=df_labels.drop('dominance',axis=1)\n",
        "df_labels=df_labels.drop('liking',axis=1)\n",
        "# print(df_labels.describe())\n",
        "print(df_labels)\n",
        "# df = df.drop('B', axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pet3Pska6SDA"
      },
      "source": [
        "# Separte Valence and Arousal to HAHV, LAHV, HALV, LALV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhIWzOBq6QSq",
        "outputId": "5f633838-f1c4-46e3-8782-4e8096d55715"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.23\n",
            "5.04\n",
            "      HAHV  LAHV  HALV  LALV\n",
            "0        1     0     0     0\n",
            "1        1     0     0     0\n",
            "2        1     0     0     0\n",
            "3        0     0     1     0\n",
            "4        0     1     0     0\n",
            "...    ...   ...   ...   ...\n",
            "1275     0     0     1     0\n",
            "1276     0     0     1     0\n",
            "1277     0     0     1     0\n",
            "1278     0     0     1     0\n",
            "1279     0     1     0     0\n",
            "\n",
            "[1280 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# # Create a sample DataFrame with 'valence' and 'arousal' columns\n",
        "# np.random.seed(0)\n",
        "# valence = np.random.uniform(1, 9, 1280)\n",
        "# arousal = np.random.uniform(1, 9, 1280)\n",
        "# data = {'valence': valence, 'arousal': arousal}\n",
        "# df_valence_arousal = pd.DataFrame(data)\n",
        "\n",
        "# Calculate the median value of arousal and valence column\n",
        "arousal_median = df_labels['arousal'].median()\n",
        "print(arousal_median)\n",
        "valence_median = df_labels['valence'].median()\n",
        "print(valence_median)\n",
        "\n",
        "# Create a new DataFrame with the desired columns\n",
        "df_result = pd.DataFrame(index=range(1280), columns=['HAHV', 'LAHV', 'HALV', 'LALV'])\n",
        "df_result[['HAHV', 'LAHV', 'HALV', 'LALV']] = 0\n",
        "\n",
        "# Apply the conditions\n",
        "df_result.loc[(df_labels['valence'] >= valence_median) & (df_labels['arousal'] >= arousal_median), 'HAHV'] = 1\n",
        "df_result.loc[(df_labels['arousal'] < arousal_median) & (df_labels['valence'] >= valence_median), 'LAHV'] = 1\n",
        "df_result.loc[(df_labels['arousal'] >= arousal_median) & (df_labels['valence'] < valence_median), 'HALV'] = 1\n",
        "df_result.loc[(df_labels['valence'] < valence_median) & (df_labels['arousal'] < arousal_median), 'LALV'] = 1\n",
        "\n",
        "# Show the first few rows of the result DataFrame\n",
        "# df_result.tail()\n",
        "print(df_result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcYaudZZDylG"
      },
      "source": [
        "Verify the data in 4 classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tc9aAzbD7U3",
        "outputId": "676249a8-cbce-4556-eccb-836e06f5f0cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of 1s in HAHV: 358\n",
            "Number of 1s in LAHV: 322\n",
            "Number of 1s in HALV: 282\n",
            "Number of 1s in LALV: 318\n",
            "Total = 1280\n"
          ]
        }
      ],
      "source": [
        "# Check the number of 1s in each individual column\n",
        "count_HAHV = df_result['HAHV'].sum()\n",
        "count_LAHV = df_result['LAHV'].sum()\n",
        "count_HALV = df_result['HALV'].sum()\n",
        "count_LALV = df_result['LALV'].sum()\n",
        "\n",
        "print(f\"Number of 1s in HAHV: {count_HAHV}\")\n",
        "print(f\"Number of 1s in LAHV: {count_LAHV}\")\n",
        "print(f\"Number of 1s in HALV: {count_HALV}\")\n",
        "print(f\"Number of 1s in LALV: {count_LALV}\")\n",
        "\n",
        "print(f\"Total = {count_HAHV+count_LAHV+count_HALV+count_LALV}\") # the total must be 1280\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Pjhzu_pQlWDv"
      },
      "outputs": [],
      "source": [
        "# Dataset with only Valence column\n",
        "df_val = df_labels['valence']\n",
        "# Dataset with only Arousal column\n",
        "df_aro = df_labels['arousal']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "u8H4KOWLll-C"
      },
      "outputs": [],
      "source": [
        "# Function to check if each trial has positive or negative valence\n",
        "def positive_valence(trial):\n",
        "    return 1 if labels[trial,0] >= np.median(labels[:,0]) else 0\n",
        "# Function to check if each trial has high or low arousal\n",
        "def high_arousal(trial):\n",
        "    return 1 if labels[trial,1] >= np.median(labels[:,1]) else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37Gsz-Z_lp_2",
        "outputId": "dfb0d97d-c83f-43c0-933a-0bd62c4892a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       High Valence  High Arousal\n",
            "count   1280.000000   1280.000000\n",
            "mean       0.531250      0.500000\n",
            "std        0.499218      0.500195\n",
            "min        0.000000      0.000000\n",
            "25%        0.000000      0.000000\n",
            "50%        1.000000      0.500000\n",
            "75%        1.000000      1.000000\n",
            "max        1.000000      1.000000\n",
            "      High Valence  High Arousal\n",
            "0                1             1\n",
            "1                1             1\n",
            "2                1             1\n",
            "3                0             1\n",
            "4                1             0\n",
            "...            ...           ...\n",
            "1275             0             1\n",
            "1276             0             1\n",
            "1277             0             1\n",
            "1278             0             1\n",
            "1279             1             0\n",
            "\n",
            "[1280 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "# Convert all ratings to boolean values\n",
        "labels_encoded = []\n",
        "for i in range (len(labels)):\n",
        "    labels_encoded.append([positive_valence(i), high_arousal(i)])\n",
        "labels_encoded = np.reshape(labels_encoded, (1280, 2))\n",
        "df_labels = pd.DataFrame(data=labels_encoded, columns=[\"High Valence\", \"High Arousal\"])\n",
        "print(df_labels.describe())\n",
        "print(df_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BrMAjqult5R",
        "outputId": "a804948d-ecca-4ace-fbdd-f2958b0d7c73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       1\n",
            "1       1\n",
            "2       1\n",
            "3       0\n",
            "4       1\n",
            "       ..\n",
            "1275    0\n",
            "1276    0\n",
            "1277    0\n",
            "1278    0\n",
            "1279    1\n",
            "Name: High Valence, Length: 1280, dtype: int64\n",
            "(1280,)\n"
          ]
        }
      ],
      "source": [
        "# Dataset with only Valence column\n",
        "df_valence = df_labels['High Valence']\n",
        "# Dataset with only Arousal column\n",
        "df_arousal = df_labels['High Arousal']\n",
        "print(df_valence)\n",
        "print(df_valence.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gh0IevZcnKtX"
      },
      "source": [
        "# FEATURE EXTRACTION USING WELCH'S METHOD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "QGtC7nRipvA8"
      },
      "outputs": [],
      "source": [
        "eeg_channels = np.array([\"Fp1\", \"AF3\", \"F3\", \"F7\", \"FC5\", \"FC1\", \"C3\", \"T7\", \"CP5\", \"CP1\", \"P3\", \"P7\", \"PO3\", \"O1\", \"Oz\", \"Pz\", \"Fp2\", \"AF4\", \"Fz\", \"F4\", \"F8\", \"FC6\", \"FC2\", \"Cz\", \"C4\", \"T8\", \"CP6\", \"CP2\", \"P4\", \"P8\", \"PO4\", \"O2\"])\n",
        "peripheral_channels = np.array([\"hEOG\", \"vEOG\", \"zEMG\", \"tEMG\", \"GSR\", \"Respiration belt\", \"Plethysmograph\", \"Temperature\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyC_7IWLp93t",
        "outputId": "ca655cf4-b79d-411c-c45b-dbb6eb1a3b47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1280, 32, 8064)\n"
          ]
        }
      ],
      "source": [
        "eeg_data = []\n",
        "for i in range (len(data)):\n",
        "  for j in range (len(eeg_channels)):\n",
        "    eeg_data.append(data[i,j])\n",
        "eeg_data = np.reshape(eeg_data, (len(data), len(eeg_channels), len(data[0,0])))\n",
        "print(eeg_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5P3G0PWqEsM",
        "outputId": "9eabdc60-3ce1-4639-9ff8-0fe87e6c8b3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1280, 8, 8064)\n"
          ]
        }
      ],
      "source": [
        "peripheral_data = []\n",
        "for i in range (len(data)):\n",
        "  for j in range (32,len(data[0])):\n",
        "    peripheral_data.append(data[i,j])\n",
        "peripheral_data = np.reshape(peripheral_data, (len(data), len(peripheral_channels), len(data[0,0])))\n",
        "print(peripheral_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Xc9rTRGHnYKt"
      },
      "outputs": [],
      "source": [
        "def bandpower(data, sf, band, window_sec=None, relative=False):\n",
        "    band = np.asarray(band)\n",
        "    low, high = band\n",
        "\n",
        "    # Define window length\n",
        "    if window_sec is not None:\n",
        "        nperseg = window_sec * sf\n",
        "    else:\n",
        "        nperseg = (2 / low) * sf\n",
        "\n",
        "    # Compute the modified periodogram (Welch)\n",
        "    freqs, psd = welch(data, sf, nperseg=nperseg)\n",
        "\n",
        "    # Frequency resolution\n",
        "    freq_res = freqs[1] - freqs[0]\n",
        "\n",
        "    # Find closest indices of band in frequency vector\n",
        "    idx_band = np.logical_and(freqs >= low, freqs <= high)\n",
        "\n",
        "    # Integral approximation of the spectrum using Simpson's rule.\n",
        "    bp = simps(psd[idx_band], dx=freq_res)\n",
        "\n",
        "    if relative:\n",
        "        bp /= simps(psd, dx=freq_res)\n",
        "    return bp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "mIxttAuQnrel"
      },
      "outputs": [],
      "source": [
        "def get_band_power(trial, channel, band):\n",
        "  bd = (0,0)\n",
        "\n",
        "  if (band == \"theta\"): # drownsiness, emotional connection, intuition, creativity\n",
        "    bd = (4,8)\n",
        "  elif (band == \"alpha\"): # reflection, relaxation\n",
        "    bd = (8,12)\n",
        "  elif (band == \"beta\"): # concentration, problem solving, memory\n",
        "    bd = (12,30)\n",
        "  elif (band == \"gamma\"): # cognition, perception, learning, multi-tasking\n",
        "    bd = (30,64)\n",
        "\n",
        "  return bandpower(eeg_data[trial,channel], 128, bd)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpNyS4s8n9Q3",
        "outputId": "d0282d2a-2441-4d0d-a1bb-47f6b608db8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.434119660168186\n",
            "5.369595513295193\n",
            "6.286556266834863\n",
            "0.9879159580139809\n"
          ]
        }
      ],
      "source": [
        "print(get_band_power(0,31,\"theta\"))\n",
        "print(get_band_power(0,31,\"alpha\"))\n",
        "print(get_band_power(0,31,\"beta\"))\n",
        "print(get_band_power(0,31,\"gamma\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8psQHMB9xqpj"
      },
      "source": [
        "# Process new datasets with 6 EEG regions and 4 band power values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "r0y_hNHIxoxi"
      },
      "outputs": [],
      "source": [
        "# Transform 1280x 32 x 8064 => 1280 x 128\n",
        "eeg_band_arr = []\n",
        "for i in range (len(eeg_data)):\n",
        "  for j in range (len(eeg_data[0])):\n",
        "    eeg_band_arr.append(get_band_power(i,j,\"theta\"))\n",
        "    eeg_band_arr.append(get_band_power(i,j,\"alpha\"))\n",
        "    eeg_band_arr.append(get_band_power(i,j,\"beta\"))\n",
        "    eeg_band_arr.append(get_band_power(i,j,\"gamma\"))\n",
        "eeg_band_arr = np.reshape(eeg_band_arr, (1280, 128))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "HVksA4V2ypUD"
      },
      "outputs": [],
      "source": [
        "frontal = np.array([\"F3\", \"FC1\", \"Fz\", \"F4\", \"FC2\"])\n",
        "parietal = np.array([\"P3\", \"P7\", \"Pz\", \"P4\", \"P8\"])\n",
        "occipital = np.array([\"O1\", \"Oz\", \"O2\", \"PO3\", \"PO4\"])\n",
        "central = np.array([\"CP5\", \"CP1\", \"Cz\", \"C4\", \"C3\", \"CP6\", \"CP2\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YQbtKTRzmdG",
        "outputId": "85ecb63c-364f-48e7-d8e6-01b2db2cf82a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                Fp1           AF3            F3            F7           FC5  \\\n",
            "count   1280.000000   1280.000000   1280.000000   1280.000000   1280.000000   \n",
            "mean     517.431002    974.493856    795.093910   1515.004071    746.435950   \n",
            "std     1165.295163   3147.555132   3020.711666   4990.544508   2188.101734   \n",
            "min        2.698928      1.995398      1.820656      3.283107      1.311200   \n",
            "25%       23.306027     17.117475     18.392335     30.827191     14.023436   \n",
            "50%       65.468048     82.102529     60.241953     91.266539     48.704968   \n",
            "75%      331.636624    304.949248    175.394835    248.308696    218.358248   \n",
            "max    15524.135098  38122.870846  39431.320394  49272.793208  20182.668545   \n",
            "\n",
            "               FC1            C3           T7           CP5          CP1  ...  \\\n",
            "count  1280.000000   1280.000000  1280.000000   1280.000000  1280.000000  ...   \n",
            "mean    345.936665    486.095113   354.004358    664.656754   276.667812  ...   \n",
            "std     717.328768   1497.636647   641.432373   2146.857585   498.823733  ...   \n",
            "min       2.025214      1.200156     3.418167      1.857737     1.340340  ...   \n",
            "25%      17.383454     18.273844    43.838157     19.178089    28.281757  ...   \n",
            "50%      55.561232     46.451432   128.629588     61.998792    60.330974  ...   \n",
            "75%     281.828747    234.342275   348.249862    312.653366   237.040645  ...   \n",
            "max    8542.244175  26021.167025  7023.985761  23255.512271  5972.589469  ...   \n",
            "\n",
            "                FC2            Cz            C4            T8           CP6  \\\n",
            "count   1280.000000   1280.000000   1280.000000   1280.000000   1280.000000   \n",
            "mean     669.953166    518.975872    471.905917    763.990397    544.785103   \n",
            "std     1714.340609   1407.210210   1896.584105   2236.655420   1563.878765   \n",
            "min        2.809501      1.637028      1.713283      2.133474      1.496299   \n",
            "25%       14.927239     23.440039      9.724978     25.143155     18.202863   \n",
            "50%       66.078472     67.044674     24.318235     90.110040     77.517763   \n",
            "75%      214.293557    305.766182    109.715681    386.232875    297.742897   \n",
            "max    18617.218099  16408.471958  24826.365142  28038.714329  19908.437378   \n",
            "\n",
            "               CP2            P4           P8           PO4            O2  \n",
            "count  1280.000000   1280.000000  1280.000000   1280.000000   1280.000000  \n",
            "mean    303.158814    527.491149   222.759444    780.700914    327.242856  \n",
            "std     650.093432   1429.084909   451.119818   1802.083002   1080.707954  \n",
            "min       1.439077      1.791296     1.641482      1.995230      3.681268  \n",
            "25%      26.754006     18.110041    18.064264     23.491991     19.333926  \n",
            "50%      88.083088     62.269206    90.914662     69.772647     49.630345  \n",
            "75%     257.959593    246.195582   225.463786    495.202699    113.117403  \n",
            "max    7210.746793  17568.065100  5487.311705  17167.017710  12314.030522  \n",
            "\n",
            "[8 rows x 32 columns]\n"
          ]
        }
      ],
      "source": [
        "eeg_theta = []\n",
        "for i in range (len(eeg_data)):\n",
        "  for j in range (len(eeg_data[0])):\n",
        "    eeg_theta.append(get_band_power(i,j,\"theta\"))\n",
        "eeg_theta = np.reshape(eeg_theta, (1280, 32))\n",
        "\n",
        "df_theta = pd.DataFrame(data = eeg_theta, columns=eeg_channels)\n",
        "print(df_theta.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1uT6ZlnzqL-",
        "outputId": "716e4245-1042-4f27-9962-258916f35a03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Fp1           AF3            F3            F7          FC5  \\\n",
            "count  1280.000000   1280.000000   1280.000000   1280.000000  1280.000000   \n",
            "mean    173.544174    333.184883    285.545436    573.725974   249.793720   \n",
            "std     378.371554   1058.758333   1036.330438   1943.692827   702.436934   \n",
            "min       2.770151      1.793012      1.724442      2.793554     0.975527   \n",
            "25%      14.082681     10.737435     10.012318     15.888935    10.074042   \n",
            "50%      33.713172     34.992442     30.026795     38.178299    20.079100   \n",
            "75%     125.508396    114.334883     73.488279     93.987498    74.040939   \n",
            "max    5627.906982  12380.702125  12764.724842  20843.070851  6575.781434   \n",
            "\n",
            "               FC1           C3           T7          CP5          CP1  ...  \\\n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000  ...   \n",
            "mean    138.011594   170.423962   124.101183   232.750895    97.610644  ...   \n",
            "std     275.218934   497.507620   200.171342   735.717912   166.430024  ...   \n",
            "min       1.682977     1.963403     2.545447     2.251935     1.682386  ...   \n",
            "25%       9.228670    10.197058    21.452775    11.461012    13.367379  ...   \n",
            "50%      24.929907    22.318468    51.473641    25.364340    26.229818  ...   \n",
            "75%     117.988147    83.518174   129.890552   110.822931    91.941255  ...   \n",
            "max    3030.077791  9215.549575  2142.437275  7894.273428  2148.109415  ...   \n",
            "\n",
            "               FC2           Cz            C4           T8          CP6  \\\n",
            "count  1280.000000  1280.000000   1280.000000  1280.000000  1280.000000   \n",
            "mean    228.331178   199.941306    193.380344   276.638039   213.620700   \n",
            "std     569.202821   578.947819    812.031964   782.782127   661.135030   \n",
            "min       2.390011     1.315395      1.227024     1.636114     2.181082   \n",
            "25%       8.715210    12.127290      6.665166    15.980086    11.300805   \n",
            "50%      26.880000    29.827367     14.169702    34.252038    31.722499   \n",
            "75%      95.964685   102.480314     40.800135   142.704220   106.673844   \n",
            "max    6038.451512  6881.486185  10501.570698  9022.269308  8394.200372   \n",
            "\n",
            "               CP2           P4           P8          PO4           O2  \n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000  \n",
            "mean    112.138023   181.507936    89.003586   269.572920   126.053116  \n",
            "std     236.260122   482.163785   186.841170   597.330120   400.465505  \n",
            "min       1.520363     2.158950     1.212432     2.002769     3.617116  \n",
            "25%      15.797490    11.564300    10.971965    13.489443    10.548845  \n",
            "50%      37.807211    28.494994    38.758864    29.247807    23.906708  \n",
            "75%      86.070815    92.261617    88.107272   162.117585    45.294454  \n",
            "max    2368.537880  5666.733316  2323.499853  5542.263376  3966.714864  \n",
            "\n",
            "[8 rows x 32 columns]\n"
          ]
        }
      ],
      "source": [
        "# Transform 880 x 32 x 8064 => 880 x 32\n",
        "eeg_alpha = []\n",
        "for i in range (len(eeg_data)):\n",
        "  for j in range (len(eeg_data[0])):\n",
        "    eeg_alpha.append(get_band_power(i,j,\"alpha\"))\n",
        "eeg_alpha = np.reshape(eeg_alpha, (1280, 32))\n",
        "\n",
        "df_alpha = pd.DataFrame(data = eeg_alpha, columns=eeg_channels)\n",
        "print(df_alpha.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUNGxdRLzvAW",
        "outputId": "5c474e1d-5f15-4161-e027-d3afeb77914c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Fp1          AF3           F3            F7          FC5  \\\n",
            "count  1280.000000  1280.000000  1280.000000   1280.000000  1280.000000   \n",
            "mean     92.200266   200.684361   193.372441    341.951096   140.642394   \n",
            "std     176.162562   668.027842   668.771074   1274.679748   386.740178   \n",
            "min       4.486703     2.650970     2.784376      3.363422     2.788531   \n",
            "25%      17.999409    13.190613    10.170223     17.951892    11.341571   \n",
            "50%      34.413828    29.155242    28.120517     33.617573    22.402198   \n",
            "75%      80.774739   107.619088    59.807546     62.087123    53.162211   \n",
            "max    3528.485435  5784.160193  5841.475721  14848.700463  3094.687504   \n",
            "\n",
            "               FC1           C3           T7          CP5          CP1  ...  \\\n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000  ...   \n",
            "mean     99.397187    96.901859    77.540922   137.387625    55.047411  ...   \n",
            "std     197.556641   247.621839    90.107877   409.366974    85.846400  ...   \n",
            "min       3.145262     2.991550     2.477519     2.886994     2.237445  ...   \n",
            "25%       8.919796     9.331138    23.668656    11.097811     9.370318  ...   \n",
            "50%      17.625226    19.698019    44.350493    22.622621    18.748879  ...   \n",
            "75%      79.066898    46.494215    93.087474    58.273844    51.308093  ...   \n",
            "max    1702.542675  5187.441594   634.645675  4094.116788  1238.024108  ...   \n",
            "\n",
            "               FC2           Cz           C4           T8          CP6  \\\n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000   \n",
            "mean    130.756212   131.961699   136.536661   178.534190   144.021213   \n",
            "std     338.843374   409.481195   603.902680   506.405387   484.806320   \n",
            "min       3.037555     1.816169     2.079646     2.429178     2.524762   \n",
            "25%       9.115906    10.803851     7.350435    17.466794    11.400277   \n",
            "50%      17.479204    25.300435    12.926731    30.157902    23.679679   \n",
            "75%      75.259937    54.745901    25.609433    93.320360    64.338413   \n",
            "max    2786.622358  4842.537927  7489.480637  4064.418656  5955.637009   \n",
            "\n",
            "               CP2           P4           P8          PO4           O2  \n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000  \n",
            "mean     74.751315   103.971557    62.850280   148.868580    90.837375  \n",
            "std     165.803855   288.941591   134.177873   329.650542   275.150372  \n",
            "min       2.272088     2.914214     3.059450     2.461123     5.084168  \n",
            "25%      13.014515    11.560334    12.312069    13.732279    11.291516  \n",
            "50%      24.705624    20.439224    27.763129    23.940855    19.688820  \n",
            "75%      53.062550    67.593128    64.187473    99.947093    36.076683  \n",
            "max    1265.234960  2533.794744  1653.743590  2516.334382  2454.759737  \n",
            "\n",
            "[8 rows x 32 columns]\n"
          ]
        }
      ],
      "source": [
        "# Transform 880 x 32 x 8064 => 880 x 32\n",
        "eeg_beta = []\n",
        "for i in range (len(eeg_data)):\n",
        "  for j in range (len(eeg_data[0])):\n",
        "    eeg_beta.append(get_band_power(i,j,\"beta\"))\n",
        "eeg_beta = np.reshape(eeg_beta, (1280, 32))\n",
        "\n",
        "df_beta = pd.DataFrame(data = eeg_beta, columns=eeg_channels)\n",
        "print(df_beta.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJP58i-60AEV",
        "outputId": "4f798e81-000c-4e36-d4fa-7e322575116a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Fp1          AF3           F3           F7          FC5  \\\n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000   \n",
            "mean     50.663247   150.492372   149.210824   122.775294    91.633571   \n",
            "std     135.591365   645.635199   632.049548   496.744509   340.562025   \n",
            "min       1.069233     1.119910     0.791859     1.177512     0.712624   \n",
            "25%       8.292302     5.605668     4.352724     7.591098     5.172920   \n",
            "50%      18.329100    14.069330    11.828027    15.919877    12.648067   \n",
            "75%      39.995543    43.454610    28.586812    36.456420    38.094737   \n",
            "max    3213.255538  6060.539788  5758.756812  6348.177208  3472.515858   \n",
            "\n",
            "               FC1           C3           T7          CP5          CP1  ...  \\\n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000  ...   \n",
            "mean     60.487715    56.236468    43.792285    77.048369    29.250057  ...   \n",
            "std     139.230040   180.285647    62.089299   267.809883    68.503827  ...   \n",
            "min       0.694928     0.684210     0.562676     0.788359     0.509259  ...   \n",
            "25%       2.666459     3.534375    10.492723     3.837095     3.156311  ...   \n",
            "50%       5.313502     9.056340    23.540152     9.532963     7.735783  ...   \n",
            "75%      41.027482    29.838450    54.382720    22.302862    18.604669  ...   \n",
            "max    1413.985901  4376.356658   809.935644  2294.561961  1011.985310  ...   \n",
            "\n",
            "               FC2           Cz           C4           T8          CP6  \\\n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000   \n",
            "mean     79.191679    56.547283    55.989289   117.745424    64.340498   \n",
            "std     306.464243   167.968314   239.143748   428.381018   199.387966   \n",
            "min       0.692350     0.395680     0.697486     1.027260     0.609425   \n",
            "25%       2.893590     3.800780     2.286229     7.221083     3.850387   \n",
            "50%       7.535055     8.493068     4.640151    17.921722    10.563661   \n",
            "75%      26.896601    20.882885    13.538524    39.981006    30.943717   \n",
            "max    2829.052404  1892.813293  3054.309237  3954.519861  2405.614840   \n",
            "\n",
            "               CP2           P4           P8          PO4           O2  \n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000  \n",
            "mean     46.943309    68.100629    29.805883    82.197819    55.821892  \n",
            "std     142.501802   265.168885    57.843154   272.880509   203.288109  \n",
            "min       0.478152     0.761387     0.804002     0.838747     0.877576  \n",
            "25%       3.849956     3.690054     4.513405     4.620006     4.380690  \n",
            "50%       8.646393     7.300040    10.911662    10.430337     6.994829  \n",
            "75%      22.614200    28.908609    26.489674    42.960182    14.567389  \n",
            "max    1426.462453  2446.765512   647.533599  2505.826127  1794.801694  \n",
            "\n",
            "[8 rows x 32 columns]\n"
          ]
        }
      ],
      "source": [
        "# Transform 880 x 32 x 8064 => 880 x 32\n",
        "eeg_gamma = []\n",
        "for i in range (len(eeg_data)):\n",
        "  for j in range (len(eeg_data[0])):\n",
        "    eeg_gamma.append(get_band_power(i,j,\"gamma\"))\n",
        "eeg_gamma = np.reshape(eeg_gamma, (1280, 32))\n",
        "\n",
        "df_gamma = pd.DataFrame(data = eeg_gamma, columns=eeg_channels)\n",
        "print(df_gamma.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "kmTpi6Qc02Bu"
      },
      "outputs": [],
      "source": [
        "# Split the data into training/testing sets\n",
        "def split_train_test(x, y):\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
        "  return x_train, x_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "cOCvaWDba3pa"
      },
      "outputs": [],
      "source": [
        "# Feature scaling\n",
        "def feature_scaling(train, test):\n",
        "  sc = StandardScaler()\n",
        "  train = sc.fit_transform(train)\n",
        "  test = sc.transform(test)\n",
        "  return train, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "EHrmKN1nf8ys"
      },
      "outputs": [],
      "source": [
        "band_names = np.array([\"theta\", \"alpha\", \"beta\", \"gamma\"])\n",
        "channel_names = np.array([\"frontal\",  \"central\", \"parietal\", \"occipital\"])\n",
        "label_names = np.array([\"valence\", \"arousal\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "tYVZwPvFgATk"
      },
      "outputs": [],
      "source": [
        "# Testing different kernels (linear, sigmoid, rbf, poly) to select the most optimal one\n",
        "clf_svm = SVC(kernel = 'rbf',random_state = 42, probability=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "t4pznSOZgHmK"
      },
      "outputs": [],
      "source": [
        "# Testing different k (odd) numbers, algorithm (auto, ball_tree, kd_tree) and weight (uniform, distance) to select the most optimal one\n",
        "clf_knn = KNeighborsClassifier(n_neighbors=5, weights='distance', algorithm='auto')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "7gi_aMFOgL08"
      },
      "outputs": [],
      "source": [
        "clf_dtree=DecisionTreeClassifier(max_depth=20,min_samples_split=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "T9hH4fktgPOX"
      },
      "outputs": [],
      "source": [
        "clf_rf=RandomForestClassifier(n_estimators=50,max_depth=20,min_samples_split=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "7lJ9wwn0gUmH"
      },
      "outputs": [],
      "source": [
        "clf_nb= GaussianNB()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "h-f5ay_0gYey"
      },
      "outputs": [],
      "source": [
        "# Testing different learning rate (alpha), solver (adam, sgd, lbfgs) and activation (relu, tanh, logistic) to select the most optimal one\n",
        "clf_mlp = MLPClassifier(solver='adam', activation='tanh', alpha=0.3, max_iter=400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "vOCq_XttoT4e"
      },
      "outputs": [],
      "source": [
        "clf_adaboost = AdaBoostClassifier(n_estimators=50, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "xJMuk2lWq8v6"
      },
      "outputs": [],
      "source": [
        "clf_xgb = xgb.XGBClassifier(learning_rate=0.1, max_depth=3, n_estimators=100, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "KFc0oT1XMHGv"
      },
      "outputs": [],
      "source": [
        "import lightgbm as lgb\n",
        "clf_lgbm = lgb.LGBMClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "G_SB4HCTNIWQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "clf_gpc = GaussianProcessClassifier(kernel=1.0 * RBF(length_scale=1.0), random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "xQ_4Dt-2N5t8"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "clf_perceptron = Perceptron(random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pheOwL8PlYt",
        "outputId": "679c4f74-166c-4e77-8838-d1fd0c91f992"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl (98.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.3.0)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.5\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost\n",
        "import catboost as cb\n",
        "clf_catboost = cb.CatBoostClassifier(iterations=1000, depth=6, learning_rate=0.1, loss_function='Logloss', verbose=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define cnn model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "def create_cnn_model(data_np):\n",
        "    model = Sequential([\n",
        "        Input(shape=(data_np.shape[1], 1)),  # Adjusted to match data_np shape\n",
        "        Conv1D(filters=64, kernel_size=1, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Dropout(0.2),\n",
        "        Conv1D(filters=64, kernel_size=1, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Dropout(0.2),\n",
        "        Flatten(),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.1),\n",
        "        Dense(2, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def train_and_evaluate_cnn(df_x, df_y):\n",
        "    # Convert dataframes to numpy arrays\n",
        "    data_np = df_x.values\n",
        "    labels_np = df_y.values\n",
        "\n",
        "    # Reshape data for CNN: (number of samples, height, width, channels)\n",
        "    # Here, height=1, width=number of features, channels=1\n",
        "    data_reshaped = data_np.reshape((data_np.shape[0], data_np.shape[1], 1))\n",
        "\n",
        "    # One-hot encode the labels\n",
        "    labels_encoded = to_categorical(labels_np)\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(data_reshaped, labels_encoded, test_size=0.20, random_state=42)\n",
        "\n",
        "    # Define the CNN model\n",
        "    model = create_cnn_model(data_np)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "    return test_loss, test_accuracy\n"
      ],
      "metadata": {
        "id": "tIwd_l6MD6dw"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define ann model\n",
        "def create_ann_model(data_scaled):\n",
        "    model = Sequential([\n",
        "        Dense(64, input_dim=data_scaled.shape[1], activation='relu'),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(2, activation='softmax')  # Assuming two classes: 0 and 1\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "\n",
        "def train_and_evaluate_ann(df_x, df_y):\n",
        "    # Convert dataframes to numpy arrays\n",
        "    data_np = df_x.values\n",
        "    labels_np = df_y.values\n",
        "\n",
        "    # Standardize the data\n",
        "    scaler = StandardScaler()\n",
        "    data_scaled = scaler.fit_transform(data_np)\n",
        "\n",
        "    # One-hot encode the labels\n",
        "    labels_encoded = to_categorical(labels_np)\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(data_scaled, labels_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Define the CNN model\n",
        "    model = create_ann_model(data_np)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "    return test_loss, test_accuracy"
      ],
      "metadata": {
        "id": "C81EuQgrZIim"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define lstm model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "def create_lstm_model(data_np):\n",
        "    model = Sequential([\n",
        "    LSTM(20, input_shape=(data_np.shape[1], 1)),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(2, activation='softmax')  # Assuming two classes: 0 and 1\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def train_and_evaluate_lstm(df_x, df_y):\n",
        "    # Convert dataframes to numpy arrays\n",
        "    data_np = df_x.values\n",
        "    labels_np = df_y.values\n",
        "\n",
        "    # Reshape data for LSTM: (samples, time_steps, features)\n",
        "    # Here, each row is treated as a sequence with a single time step\n",
        "    data_reshaped = data_np.reshape((data_np.shape[0], data_np.shape[1], 1))\n",
        "\n",
        "    # One-hot encode the labels\n",
        "    labels_encoded = to_categorical(labels_np)\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(data_reshaped, labels_encoded, test_size=0.2, random_state=42)\n",
        "    # Define the CNN model\n",
        "    model = create_lstm_model(data_np)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "    return test_loss, test_accuracy\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7hC14PKCbZUM"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "i28DLITPgfgJ"
      },
      "outputs": [],
      "source": [
        "models = []\n",
        "models.append(('SVM', clf_svm))\n",
        "models.append(('k-NN', clf_knn))\n",
        "models.append(('DT', clf_dtree))\n",
        "models.append(('RF', clf_rf))\n",
        "models.append(('NB', clf_nb))\n",
        "models.append(('MLP', clf_mlp))\n",
        "models.append(('AB', clf_adaboost))\n",
        "models.append(('XGB', clf_xgb))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imbalanced-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjABDw0eqHmm",
        "outputId": "ccb74404-18ed-47d9-f92a-dfa0057c6bf2"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "L_WzJMzsjrL4"
      },
      "outputs": [],
      "source": [
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "def run_clf_cv(band, channel, label, clf):\n",
        "  if (band == \"theta\"):\n",
        "    df_x = df_theta\n",
        "  elif (band == \"alpha\"):\n",
        "    df_x = df_alpha\n",
        "  elif (band == \"beta\"):\n",
        "    df_x = df_beta\n",
        "  elif (band == \"gamma\"):\n",
        "    df_x = df_gamma\n",
        "\n",
        "  if (channel == \"frontal\"):\n",
        "    df_x = df_x[frontal]\n",
        "  elif (channel == \"central\"):\n",
        "    df_x = df_x[central]\n",
        "  elif (channel == \"parietal\"):\n",
        "    df_x = df_x[parietal]\n",
        "  elif (channel == \"occipital\"):\n",
        "    df_x = df_x[occipital]\n",
        "\n",
        "  # df_y = df_arousal if (label == \"arousal\") else df_valence\n",
        "  # print(df_y.shape)\n",
        "  # df_y = df_result[\"HAHV\"]\n",
        "  # df_y = df_result\n",
        "  # df_y = df_y.flatten\n",
        "  # print(f\"the shape of df_y is {df_y.shape}\")\n",
        "  # print(f\"the shape of df_x is {df_x.shape}\")\n",
        "  if (label == \"HAHV\"):\n",
        "    df_y = df_result[\"HAHV\"]\n",
        "  elif (label == \"LAHV\"):\n",
        "    df_y = df_result[\"LAHV\"]\n",
        "  elif (label == \"HALV\"):\n",
        "    df_y = df_result[\"HALV\"]\n",
        "  elif (label == \"LALV\"):\n",
        "    df_y = df_result[\"LALV\"]\n",
        "\n",
        "  # print(f\"the shape of df_y is {df_y.shape}\")\n",
        "  # print(f\"the shape of df_x is {df_x.shape}\")\n",
        "  # Train-test split\n",
        "\n",
        "  # save he dataframes in csv format for analysis\n",
        "  # if (band == \"gamma\" and channel == \"frontal\" and label == \"HALV\"):\n",
        "  #   df_y.to_csv('labels.csv', index=False)\n",
        "  #   print(\"DataFrame saved to 'labels.csv'\")\n",
        "  #   df_x.to_csv('data.csv', index=False)\n",
        "  #   print(\"DataFrame saved to 'data.csv'\")\n",
        "  #   from google.colab import files\n",
        "  #   files.download('labels.csv')\n",
        "  #   files.download('data.csv')\n",
        "\n",
        "  x_train, x_test, y_train, y_test = split_train_test(df_x, df_y)\n",
        "\n",
        "  # Apply SMOTE to upsample the minority class in the training set\n",
        "  # smote = SMOTE(random_state=42)\n",
        "  # X_train_resampled, y_train_resampled = smote.fit_resample(x_train, y_train)\n",
        "\n",
        "  # Apply CV\n",
        "  x_for_kfold = np.array(x_train)\n",
        "  y_for_kfold = np.array(y_train)\n",
        "  kfold = model_selection.KFold(n_splits=10)\n",
        "\n",
        "  for i, j in kfold.split(x_for_kfold):\n",
        "   x_train2, x_test2 = x_for_kfold[i], x_for_kfold[j]\n",
        "   y_train2, y_test2 = y_for_kfold[i], y_for_kfold[j]\n",
        "\n",
        "  # Feature scaling\n",
        "  x_train2, x_test2 = feature_scaling(x_train2, x_test2)\n",
        "\n",
        "  # Feature scaling\n",
        "  scaler = StandardScaler()\n",
        "  x_train2 = scaler.fit_transform(x_train2)\n",
        "  x_test2 = scaler.transform(x_test2)\n",
        "\n",
        "  # x_train2 = X_train_resampled\n",
        "  # x_test2 = x_test\n",
        "  # y_train2 = y_train_resampled\n",
        "  # y_test2 = y_test\n",
        "\n",
        "  # Standardize the features\n",
        "  # scaler = StandardScaler()\n",
        "  # X_train_resampled = scaler.fit_transform(X_train_resampled)\n",
        "  # x_test = scaler.transform(x_test)\n",
        "\n",
        "\n",
        "  # x_train2 = x_train\n",
        "  # x_test2 = x_test\n",
        "  # y_train2 = y_train\n",
        "  # y_test2 = y_test\n",
        "  if (clf == \"svm\"):\n",
        "    clf_svm.fit(x_train2, y_train2)\n",
        "    y_predict = clf_svm.predict(x_test2)\n",
        "  elif (clf == \"knn\"):\n",
        "    clf_knn.fit(x_train2, y_train2)\n",
        "    y_predict = clf_knn.predict(x_test2)\n",
        "  elif (clf == \"dtree\"):\n",
        "    clf_dtree.fit(x_train2, y_train2)\n",
        "    y_predict = clf_dtree.predict(x_test2)\n",
        "  elif (clf == \"rf\"):\n",
        "    clf_rf.fit(x_train2, y_train2)\n",
        "    y_predict = clf_rf.predict(x_test2)\n",
        "  elif (clf == \"nb\"):\n",
        "    clf_nb.fit(x_train2, y_train2)\n",
        "    y_predict = clf_nb.predict(x_test2)\n",
        "  elif (clf == \"mlp\"):\n",
        "    clf_mlp.fit(x_train2, y_train2)\n",
        "    y_predict = clf_mlp.predict(x_test2)\n",
        "  elif (clf == \"ab\"):\n",
        "    clf_adaboost.fit(x_train2, y_train2)\n",
        "    y_predict = clf_adaboost.predict(x_test2)\n",
        "  elif (clf == \"xgb\"):\n",
        "    clf_xgb.fit(x_train2, y_train2)\n",
        "    y_predict = clf_xgb.predict(x_test2)\n",
        "  elif (clf == \"lgbm\"):\n",
        "    clf_lgbm.fit(x_train2, y_train2)\n",
        "    y_predict = clf_lgbm.predict(x_test2)\n",
        "  elif (clf == \"gpc\"):\n",
        "    clf_gpc.fit(x_train2, y_train2)\n",
        "    y_predict = clf_gpc.predict(x_test2)\n",
        "  elif (clf == \"per\"):\n",
        "    clf_perceptron.fit(x_train2, y_train2)\n",
        "    y_predict = clf_perceptron.predict(x_test2)\n",
        "  elif (clf == \"cb\"):\n",
        "    clf_catboost.fit(x_train2, y_train2)\n",
        "    y_predict = clf_catboost.predict(x_test2)\n",
        "  elif (clf == \"cnn\"):\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_accuracy = train_and_evaluate_cnn(df_x, df_y)\n",
        "    # print(f\"Test Loss: {test_loss}\")\n",
        "    # print(f\"Test Accuracy: {test_accuracy}\")\n",
        "    return \"DL\",test_loss, test_accuracy\n",
        "\n",
        "  elif(clf ==\"ann\"):\n",
        "    test_loss, test_accuracy = train_and_evaluate_ann(df_x, df_y)\n",
        "    # print(f\"Test Loss: {test_loss}\")\n",
        "    # print(f\"Test Accuracy: {test_accuracy}\")\n",
        "    return \"DL\",test_loss, test_accuracy\n",
        "  elif(clf ==\"lstm\"):\n",
        "    test_loss, test_accuracy = train_and_evaluate_lstm(df_x, df_y)\n",
        "    return \"DL\",test_loss,test_accuracy\n",
        "  return \"ML\",y_test2, y_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "gWN0kvbJjyhB"
      },
      "outputs": [],
      "source": [
        "def get_accuracy(band, channel, label, clf):\n",
        "  classifier,y_test2, y_predict = run_clf_cv(band, channel, label, clf)\n",
        "  if (classifier == \"DL\"):\n",
        "    return y_predict\n",
        "  return np.round(accuracy_score(y_test2, y_predict)*100,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "cB-1MOCIuv_M"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "def print_conf(band, channel, label, clf):\n",
        "  classifier,y_test2, y_predict = run_clf_cv(band, channel, label, clf)\n",
        "  conf_matrix = confusion_matrix(y_test2, y_predict)\n",
        "  # print(conf_matrix)\n",
        "  plt.figure(figsize=(4, 2))  # Decrease the figure size\n",
        "  plt.title('Confusion Matrix')\n",
        "  sns.heatmap(conf_matrix,\n",
        "              annot=True,\n",
        "              fmt='g',\n",
        "              xticklabels=['0','1'],\n",
        "              yticklabels=['0','1'])\n",
        "\n",
        "  # display matrix\n",
        "  plt.ylabel('True Label',fontsize=12)\n",
        "  plt.xlabel('Predicted Label',fontsize=12)\n",
        "  plt.show()\n",
        "\n",
        "  # printing the classification report aswell\n",
        "\n",
        "  class_report = classification_report(y_test2, y_predict, target_names=['0', '1'])\n",
        "  print(\"\\nClassification Report:\")\n",
        "  print(class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "_kBo9bznkFa9"
      },
      "outputs": [],
      "source": [
        "def print_accuracy(label, clf):\n",
        "  arr = []\n",
        "  for i in range (len(band_names)):\n",
        "    for j in range (len(channel_names)):\n",
        "      arr.append(get_accuracy(band_names[i], channel_names[j], label, clf))\n",
        "  arr = np.reshape(arr, (4,4))\n",
        "  df = pd.DataFrame(data = arr, index=band_names, columns=channel_names)\n",
        "\n",
        "  #print(\"Top 3 EEG regions with highest scores\")\n",
        "  #print(df.apply(lambda s: s.abs()).max().nlargest(3))\n",
        "  #print()\n",
        "  #print(\"Top 2 bands with highest scores\")\n",
        "  #print(df.apply(lambda s: s.abs()).max(axis=1).nlargest(2))\n",
        "  #print()\n",
        "  #print(\"EEG region with highest scores per each band\")\n",
        "  #print(df.idxmax(axis=1))\n",
        "  #print()\n",
        "  #print(\"Accuracy Scores\")\n",
        "  #print(df.idxmax())\n",
        "  #print()\n",
        "  print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDIaK777kOdU",
        "outputId": "358534c2-a4ef-4c93-82d5-190daee98fc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    65.69    67.65     65.69      65.69\n",
            "alpha    65.69    67.65     67.65      65.69\n",
            "beta     67.65    66.67     67.65      67.65\n",
            "gamma    65.69    66.67     67.65      66.67\n"
          ]
        }
      ],
      "source": [
        "print_accuracy('HAHV', 'svm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTqPyKdifUch",
        "outputId": "d2411f6b-2e12-4171-99cd-355be992e732"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    71.57    72.55     72.55      72.55\n",
            "alpha    71.57    72.55     72.55      72.55\n",
            "beta     71.57    72.55     72.55      72.55\n",
            "gamma    71.57    71.57     71.57      71.57\n"
          ]
        }
      ],
      "source": [
        "print_accuracy('LAHV', 'svm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "BaV8Ul3zfbVG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb855eb1-03df-4b2b-a320-1dcd81ba4252"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    81.37    81.37     81.37      81.37\n",
            "alpha    81.37    81.37     81.37      81.37\n",
            "beta     81.37    81.37     81.37      81.37\n",
            "gamma    81.37    80.39     80.39      81.37\n"
          ]
        }
      ],
      "source": [
        "print_accuracy('HALV', 'svm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "8sPz6Kjdfkia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "900ac0f9-49be-4027-bfa3-0225c4880a41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    75.49    76.47     76.47      75.49\n",
            "alpha    75.00    75.98     76.47      75.49\n",
            "beta     76.47    75.00     76.47      76.47\n",
            "gamma    76.47    76.96     76.47      76.96\n"
          ]
        }
      ],
      "source": [
        "print_accuracy('LALV', 'svm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "id": "IytKfnprYIKG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "outputId": "49370dd4-f3e9-4aef-d189-a7b4df475aa8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x200 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAADzCAYAAABNGkelAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAv+0lEQVR4nO3deVQTV/sH8G+CECICsi8uiLhvpaJVRMUFoYp1waqo1ahV0eKCqKityqKVuhRwQVFrwVr9VX2tWlsrIuKOS0Hc6oJrrRQQFbAoAZL7+4OXvEYIBghJhjyfc+ac5s6dO8/Q9snNnTt3eIwxBkIIIZzA13QAhBBClEdJmxBCOISSNiGEcAglbUII4RBK2oQQwiGUtAkhhEMoaRNCCIdQ0iaEEA6hpE0IIRxCSZvUWHp6Ojw9PWFqagoej4eDBw+qtP1Hjx6Bx+MhLi5Ope1yWZ8+fdCnTx9Nh0E0gJJ2HXH//n34+fmhefPmMDQ0hImJCdzc3LBu3Tq8efOmVs8tEolw/fp1fP3119i5cye6dOlSq+dTp4kTJ4LH48HExKTCv2N6ejp4PB54PB7Wrl1b5fYzMjIQEhKCtLQ0FURLdEE9TQdAau63337DyJEjIRAIMGHCBHTo0AFFRUU4e/YsFixYgJs3b2Lr1q21cu43b94gOTkZX331FWbOnFkr53BwcMCbN2+gr69fK+2/T7169fD69WscPnwYo0aNktu3a9cuGBoaorCwsFptZ2RkIDQ0FM2aNYOzs7PSxx07dqxa5yPcR0mb4x4+fAhfX184ODjgxIkTsLOzk+3z9/fHvXv38Ntvv9Xa+Z89ewYAaNiwYa2dg8fjwdDQsNbafx+BQAA3Nzf83//9X7mkvXv3bnh7e2P//v1qieX169eoX78+DAwM1HI+ooUY4bTp06czAOzcuXNK1S8uLmZhYWGsefPmzMDAgDk4OLDFixezwsJCuXoODg7M29ubnTlzhnXt2pUJBALm6OjIduzYIasTHBzMAMhtDg4OjDHGRCKR7J/fVnbM244dO8bc3NyYqakpMzIyYq1atWKLFy+W7X/48CEDwGJjY+WOS0xMZD179mT169dnpqambMiQIezPP/+s8Hzp6elMJBIxU1NTZmJiwiZOnMgKCgre+/cSiUTMyMiIxcXFMYFAwF6+fCnbd+nSJQaA7d+/nwFga9aske17/vw5mzdvHuvQoQMzMjJixsbG7OOPP2ZpaWmyOklJSeX+fm9fp7u7O2vfvj37448/WK9evZhQKGRz5syR7XN3d5e1NWHCBCYQCMpdv6enJ2vYsCF7+vTpe6+VcAONaXPc4cOH0bx5c/To0UOp+lOmTMGyZcvQuXNnREZGwt3dHeHh4fD19S1X9969e/j0008xYMAAfPvttzAzM8PEiRNx8+ZNAICPjw8iIyMBAGPGjMHOnTsRFRVVpfhv3ryJwYMHQywWIywsDN9++y2GDBmCc+fOVXrc8ePH4eXlhezsbISEhCAwMBDnz5+Hm5sbHj16VK7+qFGj8OrVK4SHh2PUqFGIi4tDaGio0nH6+PiAx+Ph559/lpXt3r0bbdq0QefOncvVf/DgAQ4ePIjBgwcjIiICCxYswPXr1+Hu7o6MjAwAQNu2bREWFgYAmDZtGnbu3ImdO3eid+/esnaeP3+OgQMHwtnZGVFRUejbt2+F8a1btw5WVlYQiUSQSCQAgC1btuDYsWPYsGED7O3tlb5WouU0/a1Bqi8vL48BYEOHDlWqflpaGgPApkyZIlc+f/58BoCdOHFCVubg4MAAsNOnT8vKsrOzmUAgYPPmzZOVlfWC3+5lMqZ8TzsyMpIBYM+ePVMYd0U9bWdnZ2Ztbc2eP38uK7t69Srj8/lswoQJ5c43efJkuTaHDx/OLCwsFJ7z7eswMjJijDH26aefsv79+zPGGJNIJMzW1paFhoZW+DcoLCxkEomk3HUIBAIWFhYmK7t8+XKFvyIYK+1NA2AxMTEV7nu7p80YY/Hx8QwAW7FiBXvw4AFr0KABGzZs2HuvkXAL9bQ5LD8/HwBgbGysVP0jR44AAAIDA+XK582bBwDlxr7btWuHXr16yT5bWVmhdevWePDgQbVjflfZWPihQ4cglUqVOuaff/5BWloaJk6cCHNzc1l5p06dMGDAANl1vm369Olyn3v16oXnz5/L/obKGDt2LE6ePInMzEycOHECmZmZGDt2bIV1BQIB+PzS/70kEgmeP3+OBg0aoHXr1khNTVX6nAKBAJMmTVKqrqenJ/z8/BAWFgYfHx8YGhpiy5YtSp+LcAMlbQ4zMTEBALx69Uqp+o8fPwafz0eLFi3kym1tbdGwYUM8fvxYrrxp06bl2jAzM8PLly+rGXF5o0ePhpubG6ZMmQIbGxv4+vpi7969lSbwsjhbt25dbl/btm2Rk5ODgoICufJ3r8XMzAwAqnQtgwYNgrGxMfbs2YNdu3aha9eu5f6WZaRSKSIjI9GyZUsIBAJYWlrCysoK165dQ15entLnbNSoUZVuOq5duxbm5uZIS0vD+vXrYW1trfSxhBsoaXOYiYkJ7O3tcePGjSodx+PxlKqnp6dXYTlT4g11is5RNt5aRigU4vTp0zh+/DjGjx+Pa9euYfTo0RgwYEC5ujVRk2spIxAI4OPjgx07duDAgQMKe9kAsHLlSgQGBqJ379748ccfER8fj4SEBLRv317pXxRA6d+nKq5cuYLs7GwAwPXr16t0LOEGStocN3jwYNy/fx/Jycnvrevg4ACpVIr09HS58qysLOTm5sLBwUFlcZmZmSE3N7dc+bu9eQDg8/no378/IiIi8Oeff+Lrr7/GiRMnkJSUVGHbZXHeuXOn3L7bt2/D0tISRkZGNbsABcaOHYsrV67g1atXFd68LfOf//wHffv2xfbt2+Hr6wtPT094eHiU+5so+wWqjIKCAkyaNAnt2rXDtGnTsHr1aly+fFll7RPtQEmb44KCgmBkZIQpU6YgKyur3P779+9j3bp1AEp/3gMoN8MjIiICAODt7a2yuJycnJCXl4dr167Jyv755x8cOHBArt6LFy/KHVv2kIlYLK6wbTs7Ozg7O2PHjh1ySfDGjRs4duyY7DprQ9++fbF8+XJs3LgRtra2Cuvp6emV68Xv27cPT58+lSsr+3Kp6AuuqhYuXIi//voLO3bsQEREBJo1awaRSKTw70i4iR6u4TgnJyfs3r0bo0ePRtu2beWeiDx//jz27duHiRMnAgA++OADiEQibN26Fbm5uXB3d8elS5ewY8cODBs2TOF0surw9fXFwoULMXz4cMyePRuvX7/G5s2b0apVK7kbcWFhYTh9+jS8vb3h4OCA7OxsbNq0CY0bN0bPnj0Vtr9mzRoMHDgQrq6u+Pzzz/HmzRts2LABpqamCAkJUdl1vIvP52PJkiXvrTd48GCEhYVh0qRJ6NGjB65fv45du3ahefPmcvWcnJzQsGFDxMTEwNjYGEZGRujWrRscHR2rFNeJEyewadMmBAcHy6YgxsbGok+fPli6dClWr15dpfaIFtPw7BWiInfv3mVTp05lzZo1YwYGBszY2Ji5ubmxDRs2yD04U1xczEJDQ5mjoyPT19dnTZo0qfThmne9O9VM0ZQ/xkofmunQoQMzMDBgrVu3Zj/++GO5KX+JiYls6NChzN7enhkYGDB7e3s2ZswYdvfu3XLneHda3PHjx5mbmxsTCoXMxMSEffLJJwofrnl3SmFsbCwDwB4+fKjwb8qY/JQ/RRRN+Zs3bx6zs7NjQqGQubm5seTk5Aqn6h06dIi1a9eO1atXr8KHayrydjv5+fnMwcGBde7cmRUXF8vVmzt3LuPz+Sw5ObnSayDcwWOsCndiCCGEaBSNaRNCCIdQ0iaEEA6hpE0IIRxCSZsQQjiEkjYhhHAIJW1CCFEBiUSCpUuXwtHREUKhEE5OTli+fLncQ1aMMSxbtgx2dnYQCoXw8PAo94Ty+1DSJoQQFVi1ahU2b96MjRs34tatW1i1ahVWr16NDRs2yOqsXr0a69evR0xMDC5evAgjIyN4eXlV6XV1OjFPuzhHdUuJEu0ntO/1/kqkzigpevr+SpUozlbc09W3bql0O4MHD4aNjQ22b98uKxsxYgSEQiF+/PFHMMZgb2+PefPmYf78+QCAvLw82NjYIC4urtK1bN5GPW1CiG5jUoWbWCxGfn6+3KZoLZcePXogMTERd+/eBQBcvXoVZ8+excCBAwGUvs81MzMTHh4esmNMTU3RrVs3pRZ8K0NJmxCi05ikROEWHh4OU1NTuS08PLzCdhYtWgRfX1+0adMG+vr6+PDDDxEQEIBx48YBADIzMwEANjY2csfZ2NjI9imDFowihOg2SYnCXYsXLy73pieBQFBh3b1792LXrl3YvXs32rdvj7S0NAQEBMDe3h4ikUhl4VLSJoToNqnil20IBAKFSfpdCxYskPW2AaBjx454/PgxwsPDIRKJZEv5ZmVlwc7OTnZcVlaWbDliZdDwCCFEt0lKFG9V8Pr1a9l7Qcvo6enJ3lTk6OgIW1tbJCYmyvbn5+fj4sWLcHV1Vfo81NMmhOg0VsXkrMgnn3yCr7/+Gk2bNkX79u1x5coVREREYPLkyQBK31IUEBCAFStWoGXLlnB0dMTSpUthb2+PYcOGKX0eStqEEN3GlH9nZ2U2bNiApUuX4osvvkB2djbs7e3h5+eHZcuWyeoEBQWhoKAA06ZNQ25uLnr27ImjR4/C0NBQ6fPQPG1S59A8bd1S03na4lsVv4sUAARtVfc2J1WhnjYhRLepaHhEXShpE0J0m1Q1wyPqQkmbEKLTmLRY0yFUCSVtQohuo+ERQgjhkEoertFGlLQJIbqNetqEEMIhlLQJIYRDaPYIIYRwB5PQ7BFCCOEOGh4hhBAOUdHaI+pCSZsQotuop00IIRxSQkmbEEK4g4ZHCCGEQ2h4hBBCOISSNiGEcAg9XEMIIRwioQWjCCGEO2j2CCGEcAjNHiGEEA6h4RFCCOEQGh4hhBAOoeERQgjhDlbCreERvqYDINUnkUiwYesP8Pp0Ilz6DsXHIychJnY3GGOyOgknz2FqwJdwGzgKHdwG4vbd+xqMmNSWGdNFuHf3Av7Nv4/zZw+jaxdnTYfEHRKJ4k0LUdLmsO0/7sOeg7/hy8Av8MvurQj8YjK+3/Uf7PrPL7I6bwoL0blTe8ydMVmDkZLaNHLkEKxdE4zlKyLQtdvHuHrtTxz5bResrCw0HRo3SKWKNy1EwyMclnbjFvr26g73Hh8BABrZ2eBIwilc//OOrM6Qj/sDAJ7+k6WRGEntmztnKr7bvhs7ftgLAPjCfxEGDeyPSRN9sXpNtIaj4wAt7VErolU97ZycHKxevRrDhw+Hq6srXF1dMXz4cKxZswbPnj3TdHhax7lDW1z8Iw2P/vobAHA7/QFSr91Er+5dNBwZURd9fX107twJiSfOyMoYY0g8cRbdu7toMDIOKZEo3qro6dOn+Oyzz2BhYQGhUIiOHTvijz/+kO1njGHZsmWws7ODUCiEh4cH0tPTq3QOpXrajo6O4PF4VWqYx+Ph/n3lx08vX74MLy8v1K9fHx4eHmjVqhUAICsrC+vXr8c333yD+Ph4dOlSeUISi8UQi8VyZXyxGAKBoErxc8GU8aNQ8Po1Phk7DXp8PiRSKWZPE2GwVz9Nh0bUxNLSHPXq1UN2Vo5ceXb2M7Rp7aShqDhGRbNHXr58CTc3N/Tt2xe///47rKyskJ6eDjMzM1md1atXY/369dixYwccHR2xdOlSeHl54c8//4ShoaFS51Eqabu7u1c5aVfVrFmzMHLkSMTExJQ7F2MM06dPx6xZs5CcnFxpO+Hh4QgNDZUrW7JgNpYFzVF5zJp29MRp/HosCatCgtDC0QG30x9g1botsLY0x9BBAzQdHiGcoKrZI6tWrUKTJk0QGxsrK3N0dPzfeRhDVFQUlixZgqFDhwIAfvjhB9jY2ODgwYPw9fVV6jxKJe24uLgqhF49V69eRVxcXIVfDjweD3PnzsWHH3743nYWL16MwMBAuTL+q6cqi1ObfBu9HVM+G4VBHn0AAK2cHPFPZja+27mXkraOyMl5gZKSEljbWMqVW1tbITOLhhSVUsmYdkW/3AUCQYW/3H/55Rd4eXlh5MiROHXqFBo1aoQvvvgCU6dOBQA8fPgQmZmZ8PDwkB1jamqKbt26ITk5WemkrTVj2ra2trh06ZLC/ZcuXYKNjc172xEIBDAxMZHb6uLQCAAUForB48t/yfH5fEjfmvJH6rbi4mKkpl5Dv749ZWU8Hg/9+vbEhQspGoyMQ6RM4RYeHg5TU1O5LTw8vMJmHjx4gM2bN6Nly5aIj4/HjBkzMHv2bOzYsQMAkJmZCQDl8piNjY1snzKqPXskPz8fmzZtQlJSErKzs7FlyxZ89NFHePHiBeLi4jBkyBC0aNFC6fbmz5+PadOmISUlBf3795ddWFZWFhITE7Ft2zasXbu2uuHWSX3cumHbjp9gZ2ONFo4OuHX3Hn7Y8zOGe3vK6uTlv8I/mdnIznkOAHj435uWlhZmsLQw10jcRLUi121D7PZIpKRew+XLVzB71lQYGQkRt2OPpkPjhkqGRxZ/Vf6Xu6JOoFQqRZcuXbBy5UoAwIcffogbN24gJiYGIpFIZeFWK2n//fffcHd3x5MnT9CyZUvcvn0b//77LwDA3NwcW7ZswePHj7Fu3Tql2/T394elpSUiIyOxadMmSP77k0VPTw8uLi6Ii4vDqFGjqhNunfXl3BnYsO0HrFgbjRcvc2FlaY6RQwdhxqSxsjpJZy5gycoI2ecFwd8AAGZMHgf/zz9Te8xE9fbt+wVWluYIWTYftrZWuHr1JrwHf4bs7Jz3H0wqHR5RNBRSETs7O7Rr106urG3btti/fz+A0tEEoLQjamdnJ6uTlZUFZ2dnpcOtVtJesGABXr16hbS0NFhbW8Pa2lpu/7Bhw/Drr79Wud3Ro0dj9OjRKC4uRk5O6X9wlpaW0NfXr06YdZ6RUX0sCpiORQHTFdYZ5j0Aw7xpfLuu27Q5Dps2x2k6DE5iKnqIxs3NDXfu3JEru3v3LhwcHACU3pS0tbVFYmKiLEnn5+fj4sWLmDFjhtLnqVbSPnbsGObOnYt27drh+fPn5fY3b94cT548qU7TAErnnr79TUQIIbWmRDVJe+7cuejRowdWrlyJUaNG4dKlS9i6dSu2bt0KoPReQ0BAAFasWIGWLVvKpvzZ29tj2LBhSp+nWkn7zZs3sLKyUrj/1atX1WmWEELUT0VPRHbt2hUHDhzA4sWLERYWBkdHR0RFRWHcuHGyOkFBQSgoKMC0adOQm5uLnj174ujRo0rP0QYAHmNVn2rQpUsXtG7dGrt27cLz589hZWWF48ePo1+/0oc6evbsCT09PZw6daqqTdeK4pwHmg6BqJHQvpemQyBqVFJUsym9rwI+UbjPOOpwjdquDdXqaQcEBEAkEqFTp04YOXIkgNI7p/fu3UNoaCiSk5Nlg++EEKLVOLY0a7WS9meffYbHjx9jyZIl+OqrrwAAH3/8MRhj4PP5WLlyZZXGaAghRGNUNKatLtWep/3VV19h/Pjx2L9/P+7duwepVAonJyf4+PigefPmqoyREEJqTTVGiDWqRkuzNm3aFHPnzlVVLIQQon660tMGgBs3buDIkSN49OgRgNJ5iB9//DE6duyoitgIIaTWMV1I2mKxGH5+fti5c6dsHBsovRm5aNEijBs3Dt999x0MDAxUGiwhhKgct3J29RaMWrhwIX744QfMmDEDt27dQmFhIcRiMW7duoXp06fjxx9/RFBQkKpjJYQQlWMlUoWbNqrWPG1LS0t4e3vLVq961/jx4/H777/LHkXXNJqnrVtonrZuqek87Zcj+yjcZ7bvZI3arg3V6mkXFxeje/fuCvf36NEDJSUl1Q6KEELURlrJpoWqlbS9vLwQHx+vcP/Ro0fh6empcD8hhGgLVsIUbtpIqRuRL168kPu8fPlyjBo1Cj4+PvD395etm52eno7o6Gg8fvwYe/bQWr6EEO3HODYooNSYNp/Pr/C9jQAUlvP5fK0ZIqExbd1CY9q6paZj2jkD3RXus/xdO9ZPeptSPe1ly5bV+ot9CSFEE7jW01YqaYeEhNRyGIQQohnSupi0CSGkzmLcGkWoUdI+d+4cUlNTkZeXB+k7r+zh8XhYunRpjYIjhJDaJi3RgaT94sULeHt749KlS2CMgcfjyd2YLCujpE0I0XZSCbeSdrXmaS9YsADXrl3D7t278eDBAzDGEB8fj7t372L69OlwdnZGRkaGqmMlhBCVY1LFmzaqVtI+cuQI/Pz8MHr0aBgbG5c2xOejRYsWiI6ORrNmzRAQEKDKOAkhpFZIJTyFmzaqVtLOzc1F+/btAQANGjQAAPz777+y/Z6enpU+MUkIIdpCWsJXuGmjakVlb2+PzMxMAIBAIIC1tTWuXr0q2//06VOa100I4QTGFG/aqFo3Inv37o2EhATZ+yFHjx6N1atXQ09PD1KpFFFRUfDy8lJpoIQQUhukEu3sUStSraQdGBiIhIQEiMViCAQChISE4ObNm7LZIr1798b69etVGighhNQGbb3hqEi11tNWJDc3F3p6erKbk9qC1h7RLbT2iG6p6dojd9oMVLiv9e3fa9R2bVDp74KGDRvC2NgYu3fvpqVZCSGcwLXZI7XyGPvDhw+RmJhYG00TQohKMal2JmdFaO0RQohOk0i5dSOSW9ESQoiKSaQ8hVtNfPPNN+DxeHIPGhYWFsLf3x8WFhZo0KABRowYgaysrCq1S0mbEKLTGOMp3Krr8uXL2LJlCzp16iRXPnfuXBw+fBj79u3DqVOnkJGRAR8fnyq1TUmbEKLTVN3T/vfffzFu3Dhs27YNZmZmsvK8vDxs374dERER6NevH1xcXBAbG4vz58/jwoULSrev9Jj2u98YlcnOzla6rjp80WWhpkMghGipysa0xWIxxGKxXJlAIIBAIFB4jL+/P7y9veHh4YEVK1bIylNSUlBcXAwPDw9ZWZs2bdC0aVMkJyeje/fuSsWrdNI2NzdX+tF0CwsLtG3bVtmmCSFEYyp7UCU8PByhoaFyZcHBwQrf5vXTTz8hNTUVly9fLrcvMzMTBgYGaNiwoVy5jY2NbFkQZSidtE+ePKl0o4QQwhWV9bQXL16MwMBAuTJFvewnT55gzpw5SEhIgKGhoUpjfBtN+SOE6DQJFI8gvG8o5G0pKSnIzs5G586d/9e2RILTp09j48aNiI+PR1FREXJzc+V621lZWbC1tVU6XkrahBCdJlXRQh79+/fH9evX5comTZqENm3aYOHChWjSpAn09fWRmJiIESNGAADu3LmDv/76C66urkqfh5I2IUSnSVQ0ic7Y2BgdOnSQKzMyMoKFhYWs/PPPP0dgYCDMzc1hYmKCWbNmwdXVVembkAAlbUKIjqtseETVIiMjwefzMWLECIjFYnh5eWHTpk1VakOlq/xpq6nNRmo6BKJGsRnnNR0CUaOarvJ31MZX4b6Ps36qUdu1gXrahBCdps6etirUKGk/ffoUp0+fRnZ2NkaMGIHGjRtDIpEgLy8Ppqam0NPTU1WchBBSK0o49mrEao3AM8YQGBgIR0dHjBs3DoGBgbh79y6A0kc4mzVrhg0bNqg0UEIIqQ2skk0bVStpr1mzBuvWrcP8+fORkJCAt4fFTU1N4ePjg/3796ssSEIIqS0lPJ7CTRtVK2lv27YNEyZMwMqVK+Hs7Fxuf6dOnWQ9b0II0WaSSjZtVK0x7SdPnqBHjx4K9xsZGSE/P7/aQRFCiLpw7MU11Uva1tbWePLkicL9KSkpaNq0abWDIoQQdeHa7JFqDY/4+PggJiYGDx787y3nZSsAHjt2DHFxcRg5kuZGE0K0XwlP8aaNqpW0Q0NDYWdnB2dnZ0yYMAE8Hg+rVq1Cz549MXDgQHTq1AlffvmlqmMlhBCV04nZI6amprhw4QKCgoLw9OlTGBoa4tSpU8jNzUVwcDDOnDmD+vXrqzpWQghROa71tKv9cI1QKMSSJUuwZMkSVcZDCCFqJdHS5KwIPcZOCNFpUk0HUEXVStqTJ09+bx0ej4ft27dXp3lCCFEbbZ2PrUi1kvaJEyfKvS9SIpHgn3/+gUQigZWVFYyMjFQSICGE1CZtHbtWpFpJ+9GjRxWWFxcXY8uWLYiKikJCQkJN4iKEELXg2vCIal7Z8F/6+vqYOXMmPD09MXPmTFU2TQghtULCU7xpI5Um7TIffPABTp8+XRtNE0KISunE2iPvk5CQQPO0CSGcINXax2gqVq2kHRYWVmF5bm4uTp8+jdTUVCxatKhGgRFCiDpoa49akWol7ZCQkArLzczM4OTkhJiYGEydOrUmcRFCiFroxOwRqZRr91sJIaRiXBseqfKNyDdv3iAwMBCHDx+ujXgIIUStuHYjsspJWygUYsuWLcjKyqqNeAghRK0kYAo3bVSt4REXFxfcuHFD1bEQQojacW2wt1rztKOiovDTTz/hu+++Q0lJiapjIoQQtamzPe3Tp0+jbdu2sLKygkgkAp/Ph5+fH2bPno1GjRpBKBTK1efxeLh69arKAyb/M/CLYejs1Q22To1QVFiE+6l3sP+bXch6kCGr02uMB7oN7Ymm7R0hNK6P2Z1EeJP/WoNRk9owY7oI8wJnwNbWCteu/Yk5AUtx+Y80TYfFCdqanBVRuqfdt29fHD9+HABgYWGB1q1bo3fv3ujWrRsaN24MCwsLuc3c3LzWgialWnVrj6Sd8Qgf/iUixy+HXr16mPvDEhgIBbI6BkID3DiVhiObDmgwUlKbRo4cgrVrgrF8RQS6dvsYV6/9iSO/7YKVlYWmQ+MEaSWbNlK6p80YA2Ol30gnT56srXhIFawTfS33OXZ+NCJTt8OhY3OkX7oFAEj8/ggAoFX3dmqPj6jH3DlT8d323djxw14AwBf+izBoYH9MmuiL1WuiNRyd9lNVTzs8PBw///wzbt++DaFQiB49emDVqlVo3bq1rE5hYSHmzZuHn376CWKxGF5eXti0aRNsbGyUPk+trD1CNENoXLp0QEHuvxqOhKiLvr4+OnfuhMQTZ2RljDEknjiL7t1dNBgZd5SAKdyq4tSpU/D398eFCxeQkJCA4uJieHp6oqCgQFZn7ty5OHz4MPbt24dTp04hIyMDPj4+VTpPlWaPvLuGtro9efIEwcHB+P777xXWEYvFEIvFcmUSJoEeT6+2w9MoHo8H32UTkX75NjLuPtF0OERNLC3NUa9ePWRn5ciVZ2c/Q5vWThqKiluYinraR48elfscFxcHa2trpKSkoHfv3sjLy8P27duxe/du9OvXDwAQGxuLtm3b4sKFC+jevbtS56lST/uzzz6Dnp6eUlu9eqpfi+rFixfYsWNHpXXCw8Nhamoqt6Xl3VZ5LNpm7PIpsG/dBNtmRWo6FEI4pbLZI2KxGPn5+XLbu51CRfLy8gBAdn8vJSUFxcXF8PDwkNVp06YNmjZtiuTkZKXjrVJm9fDwQKtWrapySJX88ssvle5/8ODBe9tYvHgxAgMD5coCOk6sSVhab0zo5+jUrzPWjArGy8wXmg6HqFFOzguUlJTA2sZSrtza2gqZWc80FBW3lDDFPe3w8HCEhobKlQUHBytcf6mMVCpFQEAA3Nzc0KFDBwBAZmYmDAwM0LBhQ7m6NjY2yMzMVDreKiVtkUiEsWPHVuWQKhk2bBh4PJ7shmdF3jdEIxAIIBAI5Mrq8tDImNDP8aHXR1jrG4ycv7M1HQ5Rs+LiYqSmXkO/vj3xyy/xAEr/H+nXtyc2bY7VcHTcUNngSEWdwHfzS0X8/f1x48YNnD17tobRladVNyLt7Ozw888/QyqVVrilpqZqOkStMnb5FHQf3gvfzVmHwoJCmFg1hIlVQ+gLDGR1TKwaokm7ZrB2sAUANG7dFE3aNUN90waaCpuoWOS6bZjy+ViMHz8Sbdq0QPTGb2BkJETcjj2aDo0TJJAq3AQCAUxMTOS29yXtmTNn4tdff0VSUhIaN24sK7e1tUVRURFyc3Pl6mdlZcHW1lbpeGvlJQjV5eLigpSUFAwdOrTC/e/rheuavuO9AAAL9sj/fIudH43z/zkJAHAfNwBDAkbJ9gXtW16uDuG2fft+gZWlOUKWzYetrRWuXr0J78GfITs75/0HkyrPElGEMYZZs2bhwIEDOHnyJBwdHeX2u7i4QF9fH4mJiRgxYgQA4M6dO/jrr7/g6uqq9Hm0KmkvWLBAbnrMu1q0aIGkpCQ1RqTdpjYb+d46h6P24XDUPjVEQzRp0+Y4bNocp+kwOElVs0f8/f2xe/duHDp0CMbGxrJxalNTUwiFQpiamuLzzz9HYGAgzM3NYWJiglmzZsHV1VXpmSNAFZK2OtbQ7tWrV6X7jYyM4O7uXutxEEJ0h0RFv943b94MAOjTp49ceWxsLCZOnAgAiIyMBJ/Px4gRI+QerqkKreppE0KIuqlyeOR9DA0NER0djejo6j+pSkmbEKLTVDU8oi6UtAkhOk3CtHVpqIpR0iaE6DSuLc1KSZsQotO49mJfStqEEJ1GwyOEEMIhlLQJIYRDuDU4QkmbEKLjSrT2xWIVo6RNCNFpNDxCCCEcQg/XEEIIh1BPmxBCOISSNiGEcAgNjxBCCIdQT5sQQjiEkjYhhHCIlGOvMKSkTQjRadTTJoQQDpEyiaZDqBJK2oQQnUZLsxJCCIfQ8AghhHCIREpJmxBCOIMeriGEEA6h4RFCCOEQRvO0CSGEO2hMmxBCOISGRwghhEO49hg7X9MBEEKIJkmYVOFWHdHR0WjWrBkMDQ3RrVs3XLp0SaXxUtImhOg0KZMq3Kpqz549CAwMRHBwMFJTU/HBBx/Ay8sL2dnZKouXkjYhRKcxxhRuVRUREYGpU6di0qRJaNeuHWJiYlC/fn18//33KouXkjYhRKdJGVO4icVi5Ofny21isbjCdoqKipCSkgIPDw9ZGZ/Ph4eHB5KTk1UWr07ciNz2aJ+mQ1A7sViM8PBwLF68GAKBQNPhqNU2TQegAbr877umSoqeKtwXEhKC0NBQubLg4GCEhISUq5uTkwOJRAIbGxu5chsbG9y+fVslsQIAj3FtZjlRSn5+PkxNTZGXlwcTExNNh0NqGf37rh1isbhcz1ogEFT4xZiRkYFGjRrh/PnzcHV1lZUHBQXh1KlTuHjxokpi0omeNiGEVIeiBF0RS0tL6OnpISsrS648KysLtra2KouJxrQJIUQFDAwM4OLigsTERFmZVCpFYmKiXM+7pqinTQghKhIYGAiRSIQuXbrgo48+QlRUFAoKCjBp0iSVnYOSdh0lEAgQHBxMN6V0BP371g6jR4/Gs2fPsGzZMmRmZsLZ2RlHjx4td3OyJuhGJCGEcAiNaRNCCIdQ0iaEEA6hpE0IIRxCSZsQQjiEknYdVdvLQxLtcPr0aXzyySewt7cHj8fDwYMHNR0SqWWUtOsgdSwPSbRDQUEBPvjgA0RHR2s6FKImNOWvDurWrRu6du2KjRs3Aih9KqtJkyaYNWsWFi1apOHoSG3h8Xg4cOAAhg0bpulQSC2innYdo67lIQkhmkFJu46pbHnIzMxMDUVFCFEVStqEEMIhlLTrGHUtD0kI0QxK2nWMupaHJIRoBq3yVwepY3lIoh3+/fdf3Lt3T/b54cOHSEtLg7m5OZo2barByEhtoSl/ddTGjRuxZs0a2fKQ69evR7du3TQdFlGxkydPom/fvuXKRSIR4uLi1B8QqXWUtAkhhENoTJsQQjiEkjYhhHAIJW1CCOEQStqEEMIhlLQJIYRDKGkTQgiHUNImhBAOoaRNCCEcQkmb1JpmzZph4sSJss8nT54Ej8fDyZMnNRbTu96NUR369OmDDh06qLRNTVwH0QxK2nVUXFwceDyebDM0NESrVq0wc+bMcisAarsjR44gJCREozHweDzMnDlTozEQAtCCUXVeWFgYHB0dUVhYiLNnz2Lz5s04cuQIbty4gfr166s1lt69e+PNmzcwMDCo0nFHjhxBdHS0xhM3IdqAknYdN3DgQHTp0gUAMGXKFFhYWCAiIgKHDh3CmDFjKjymoKAARkZGKo+Fz+fD0NBQ5e0SoktoeETH9OvXD0DpEp4AMHHiRDRo0AD379/HoEGDYGxsjHHjxgEoXYc7KioK7du3h6GhIWxsbODn54eXL1/KtckYw4oVK9C4cWPUr18fffv2xc2bN8udW9GY9sWLFzFo0CCYmZnByMgInTp1wrp162Txlb1p/O3hnjKqjrEmDh06BG9vb9jb20MgEMDJyQnLly+HRCKpsH5KSgp69OgBoVAIR0dHxMTElKsjFosRHByMFi1aQCAQoEmTJggKCoJYLFZp7IQ7qKetY+7fvw8AsLCwkJWVlJTAy8sLPXv2xNq1a2XDJn5+foiLi8OkSZMwe/ZsPHz4EBs3bsSVK1dw7tw56OvrAwCWLVuGFStWYNCgQRg0aBBSU1Ph6emJoqKi98aTkJCAwYMHw87ODnPmzIGtrS1u3bqFX3/9FXPmzIGfnx8yMjKQkJCAnTt3ljteHTEqKy4uDg0aNEBgYCAaNGiAEydOYNmyZcjPz8eaNWvk6r58+RKDBg3CqFGjMGbMGOzduxczZsyAgYEBJk+eDKD0C2nIkCE4e/Yspk2bhrZt2+L69euIjIzE3bt3cfDgQZXFTjiEkTopNjaWAWDHjx9nz549Y0+ePGE//fQTs7CwYEKhkP3999+MMcZEIhEDwBYtWiR3/JkzZxgAtmvXLrnyo0ePypVnZ2czAwMD5u3tzaRSqazel19+yQAwkUgkK0tKSmIAWFJSEmOMsZKSEubo6MgcHBzYy5cv5c7zdlv+/v6sov9UayNGRQAwf3//Suu8fv26XJmfnx+rX78+KywslJW5u7szAOzbb7+VlYnFYubs7Mysra1ZUVERY4yxnTt3Mj6fz86cOSPXZkxMDAPAzp07JytzcHBQ6joI99HwSB3n4eEBKysrNGnSBL6+vmjQoAEOHDiARo0aydWbMWOG3Od9+/bB1NQUAwYMQE5OjmxzcXFBgwYNkJSUBAA4fvw4ioqKMGvWLLlhi4CAgPfGduXKFTx8+BABAQFo2LCh3L6321JEHTFWhVAolP3zq1evkJOTg169euH169e4ffu2XN169erBz89P9tnAwAB+fn7Izs5GSkqK7Pratm2LNm3ayF1f2RBX2fUR3ULDI3VcdHQ0WrVqhXr16sHGxgatW7cGny//XV2vXj00btxYriw9PR15eXmwtrausN3s7GwAwOPHjwEALVu2lNtvZWUFMzOzSmMrG6qp7pxldcRYFTdv3sSSJUtw4sQJ5Ofny+3Ly8uT+2xvb1/uZm+rVq0AAI8ePUL37t2Rnp6OW7duwcrKqsLzlV0f0S2UtOu4jz76SDZ7RBGBQFAukUulUlhbW2PXrl0VHqMokaiTNsWYm5sLd3d3mJiYICwsDE5OTjA0NERqaioWLlwIqVRa5TalUik6duyIiIiICvc3adKkpmETDqKkTSrk5OSE48ePw83NTe5n/7scHBwAlPZ6mzdvLit/9uxZuRkcFZ0DAG7cuAEPDw+F9RQNlagjRmWdPHkSz58/x88//4zevXvLystm6bwrIyOj3NTKu3fvAih9uhEovb6rV6+if//+Sg0XEd1AY9qkQqNGjYJEIsHy5cvL7SspKUFubi6A0jFzfX19bNiwAeyt141GRUW99xydO3eGo6MjoqKiZO2VebutssT2bh11xKgsPT29cnEXFRVh06ZNFdYvKSnBli1b5Opu2bIFVlZWcHFxAVB6fU+fPsW2bdvKHf/mzRsUFBSoLH7CHdTTJhVyd3eHn58fwsPDkZaWBk9PT+jr6yM9PR379u3DunXr8Omnn8LKygrz589HeHg4Bg8ejEGDBuHKlSv4/fffYWlpWek5+Hw+Nm/ejE8++QTOzs6YNGkS7OzscPv2bdy8eRPx8fEAIEtis2fPhpeXF/T09ODr66uWGN/2xx9/YMWKFeXK+/Tpgx49esDMzAwikQizZ88Gj8fDzp075ZL42+zt7bFq1So8evQIrVq1wp49e5CWloatW7fKpimOHz8ee/fuxfTp05GUlAQ3NzdIJBLcvn0be/fuRXx8/HuHvkgdpNG5K6TWlE35u3z5cqX1RCIRMzIyUrh/69atzMXFhQmFQmZsbMw6duzIgoKCWEZGhqyORCJhoaGhzM7OjgmFQtanTx9248aNctPQ3p3yV+bs2bNswIABzNjYmBkZGbFOnTqxDRs2yPaXlJSwWbNmMSsrK8bj8cpN/1NljIoAULgtX76cMcbYuXPnWPfu3ZlQKGT29vYsKCiIxcfHl7tmd3d31r59e/bHH38wV1dXZmhoyBwcHNjGjRvLnbeoqIitWrWKtW/fngkEAmZmZsZcXFxYaGgoy8vLk9WjKX+6g8eYgq4AIYQQrUNj2oQQwiGUtAkhhEMoaRNCCIdQ0iaEEA6hpE0IIRxCSZsQQjiEkjYhhHAIJW1CCOEQStqEEMIhlLQJIYRDKGkTQgiHUNImhBAO+X8NUiL4IQ4mOAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      1.00      0.89        81\n",
            "           1       0.00      0.00      0.00        21\n",
            "\n",
            "    accuracy                           0.79       102\n",
            "   macro avg       0.40      0.50      0.44       102\n",
            "weighted avg       0.63      0.79      0.70       102\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "print_conf(\"gamma\",\"occipital\",\"LALV\",\"svm\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HAHV\",\"knn\")"
      ],
      "metadata": {
        "id": "3ZJ1eRTBagJU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7af15173-0f88-4a43-d31c-39c717076386"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    54.90    58.82     55.88      55.88\n",
            "alpha    62.75    64.71     65.69      59.80\n",
            "beta     58.82    61.76     69.61      60.78\n",
            "gamma    67.65    63.73     63.73      62.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LAHV\",\"knn\")"
      ],
      "metadata": {
        "id": "47cLDLLtc3dL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03ffac41-26aa-4c0b-f8d3-8ee56e015fee"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    71.57    68.63     70.59      63.73\n",
            "alpha    70.59    67.65     69.61      73.53\n",
            "beta     66.67    64.71     69.61      66.67\n",
            "gamma    72.55    70.59     66.67      70.59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HALV\",\"knn\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3_ANNm2g7jl",
        "outputId": "23d772a1-ca6f-4859-c02f-5972549e0bfe"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    79.41    76.47     77.45      82.35\n",
            "alpha    84.31    73.53     75.49      74.51\n",
            "beta     80.39    80.39     77.45      80.39\n",
            "gamma    79.41    78.43     79.41      76.47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LALV\",\"knn\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBuNsO0whCji",
        "outputId": "490a6d93-fa72-402a-8ea3-26e7f39497cc"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    70.59    75.49     67.65      69.61\n",
            "alpha    74.51    75.49     76.47      74.51\n",
            "beta     76.47    76.47     79.41      70.59\n",
            "gamma    72.55    72.55     77.45      70.59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HAHV\",\"dtree\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7McLqGAXhFmh",
        "outputId": "a0e70447-80bc-4bdd-e08f-2f289403c5ff"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    61.76    57.84     54.90      52.94\n",
            "alpha    51.96    58.82     56.86      60.78\n",
            "beta     64.71    56.86     59.80      62.75\n",
            "gamma    70.59    63.73     60.78      69.61\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LAHV\",\"dtree\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qyAj7CdhLoh",
        "outputId": "96b70d02-24bd-46b5-b4a9-cc01c425b039"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    64.71    62.75     65.69      63.73\n",
            "alpha    68.63    72.55     64.71      60.78\n",
            "beta     60.78    65.69     57.84      56.86\n",
            "gamma    59.80    72.55     59.80      63.73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HALV\",\"dtree\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5iFr3h1hODL",
        "outputId": "0c9bbbca-64e1-4ed4-dc6a-dc69092439bf"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    68.63    67.65     75.49      70.59\n",
            "alpha    74.51    61.76     67.65      63.73\n",
            "beta     76.47    72.55     71.57      67.65\n",
            "gamma    81.37    76.47     72.55      74.51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LALV\",\"dtree\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQY984Z4hTAg",
        "outputId": "5f487ee8-cb59-46be-8c04-411927feda46"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    68.63    67.65     71.57      64.71\n",
            "alpha    68.63    65.69     60.78      71.57\n",
            "beta     66.67    69.61     67.65      70.59\n",
            "gamma    73.53    70.59     70.59      60.78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HAHV\",\"rf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XazVDwjhVW0",
        "outputId": "7b75eae9-70fc-4136-eedc-1c054844ad04"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    62.75    60.78     61.76      60.78\n",
            "alpha    64.71    65.69     65.69      60.78\n",
            "beta     61.76    59.80     67.65      64.71\n",
            "gamma    67.65    65.69     67.65      74.51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LAHV\",\"rf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6V2n3jahc5l",
        "outputId": "ed615e14-6690-4f7a-e291-3bcfd31609cd"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    70.59    70.59     66.67      68.63\n",
            "alpha    69.61    72.55     72.55      69.61\n",
            "beta     68.63    73.53     67.65      69.61\n",
            "gamma    76.47    75.49     72.55      71.57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HALV\",\"rf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_947cDehfTh",
        "outputId": "64a2f272-cb18-4d13-a1da-5316377f1f4e"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    79.41    76.47     79.41      78.43\n",
            "alpha    83.33    79.41     79.41      78.43\n",
            "beta     78.43    79.41     84.31      81.37\n",
            "gamma    81.37    83.33     84.31      80.39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LALV\",\"rf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpaIBT6chh-J",
        "outputId": "d115a5f5-09c3-4478-b356-4bae5f7ea188"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    75.49    74.51     75.49      73.53\n",
            "alpha    76.47    76.47     81.37      75.49\n",
            "beta     76.47    77.45     77.45      74.51\n",
            "gamma    74.51    77.45     77.45      73.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HAHV\",\"nb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48cd7Ye-hlP9",
        "outputId": "dfa6f3b9-a0e3-404a-9379-36205847fdeb"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    62.75    38.24     61.76      62.75\n",
            "alpha    62.75    40.20     62.75      67.65\n",
            "beta     62.75    39.22     67.65      67.65\n",
            "gamma    67.65    40.20     67.65      67.65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LAHV\",\"nb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cw1gw4y-hvol",
        "outputId": "8e4ef268-8756-4e08-f0ad-510c351f0349"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    39.22    72.55     74.51      35.29\n",
            "alpha    40.20    72.55     74.51      36.27\n",
            "beta     36.27    73.53     73.53      33.33\n",
            "gamma    32.35    73.53     72.55      28.43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HALV\",\"nb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jpmOw5XhzK7",
        "outputId": "48cab857-e72d-440a-b7db-01a986ec38e7"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    80.39    28.43     80.39      80.39\n",
            "alpha    80.39    27.45     78.43      80.39\n",
            "beta     80.39    81.37     79.41      78.43\n",
            "gamma    78.43    77.45     78.43      80.39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LALV\",\"nb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpIC6lTMh3XK",
        "outputId": "dfd9ea3d-e936-4f72-979c-f8cd070d28f1"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    71.57    73.53     76.47      73.53\n",
            "alpha    70.59    72.55     76.47      73.53\n",
            "beta     71.57    70.59     53.92      75.49\n",
            "gamma    77.45    76.47     79.41      77.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HAHV\",\"mlp\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnJufSQEk3gr",
        "outputId": "f3ade79d-ef01-4397-f7a1-585ce0472a33"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    67.65    67.65     67.65      67.65\n",
            "alpha    67.65    66.67     67.65      67.65\n",
            "beta     67.65    66.67     67.65      67.65\n",
            "gamma    68.63    66.67     67.65      67.65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LAHV\",\"mlp\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hE7LJGYYlNmD",
        "outputId": "57afe634-9dc0-4699-b8e6-b90d1cf69c19"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    71.57    72.55     72.55      72.55\n",
            "alpha    71.57    72.55     72.55      72.55\n",
            "beta     71.57    72.55     72.55      72.55\n",
            "gamma    71.57    70.59     70.59      71.57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HALV\",\"mlp\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRT6VcEclUkW",
        "outputId": "426a6a2f-50ab-40f6-c3c1-09cf291f1581"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    81.37    81.37     81.37      81.37\n",
            "alpha    81.37    81.37     81.37      81.37\n",
            "beta     81.37    82.35     81.37      81.37\n",
            "gamma    81.37    81.37     80.39      80.39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LALV\",\"mlp\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpNkotrVlZWu",
        "outputId": "a6f70d22-d92d-463c-c7b1-efc5b8b74a9e"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    76.47    77.45     78.43      77.45\n",
            "alpha    77.45    77.45     78.43      76.47\n",
            "beta     79.41    77.45     79.41      77.45\n",
            "gamma    79.41    79.41     79.41      79.41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HAHV\",\"ab\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erYq7nicnROs",
        "outputId": "f826c13e-2d52-41b9-da71-dce8f5c94c97"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    64.71    62.75     65.69      63.73\n",
            "alpha    63.73    67.65     63.73      67.65\n",
            "beta     65.69    68.63     68.63      67.65\n",
            "gamma    66.67    63.73     65.69      66.67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LAHV\",\"ab\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fPMwhsXnX2f",
        "outputId": "3e99399c-f740-459b-a024-2ca761df486e"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    70.59    72.55     71.57      68.63\n",
            "alpha    71.57    74.51     71.57      71.57\n",
            "beta     70.59    73.53     73.53      73.53\n",
            "gamma    72.55    73.53     72.55      70.59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HALV\",\"ab\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1BAgu7lncbF",
        "outputId": "bcce5299-d9e6-43c0-ae7b-8e93f071d7ac"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    82.35    79.41     81.37      76.47\n",
            "alpha    79.41    81.37     77.45      79.41\n",
            "beta     78.43    79.41     81.37      79.41\n",
            "gamma    78.43    78.43     79.41      77.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LALV\",\"ab\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EtZqaWJngRs",
        "outputId": "5b10ebe9-0763-4a49-9498-afd54604a82b"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    75.49    77.45     77.45      77.45\n",
            "alpha    75.49    76.47     77.45      77.45\n",
            "beta     73.53    77.45     81.37      77.45\n",
            "gamma    77.45    75.49     77.45      74.51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HAHV\",\"xgb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fdCu6AonjgZ",
        "outputId": "2a3cddd6-ed5b-465e-dc8f-be2e1df85088"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    58.82    66.67     65.69      62.75\n",
            "alpha    67.65    66.67     69.61      65.69\n",
            "beta     71.57    63.73     69.61      64.71\n",
            "gamma    70.59    62.75     71.57      70.59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LAHV\",\"xgb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wo9lY7kynp5r",
        "outputId": "6e34660a-4d4e-4c93-d005-52581c64e653"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    75.49    74.51     70.10      75.98\n",
            "alpha    75.98    75.00     74.51      76.47\n",
            "beta     75.98    75.98     75.49      75.98\n",
            "gamma    75.49    75.49     75.49      75.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HALV\",\"xgb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkJk2VfvnuWW",
        "outputId": "f8e1731e-2fd0-4d67-e291-63ab8222ca8e"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    80.39    81.37     80.39      80.39\n",
            "alpha    82.35    81.37     78.43      79.41\n",
            "beta     82.35    80.39     80.39      81.37\n",
            "gamma    80.39    79.41     82.35      77.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LALV\",\"xgb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDRn39Jknwj8",
        "outputId": "4e7b1118-4ccc-49f2-f450-1816344c123b"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    75.49    77.45     76.47      78.43\n",
            "alpha    76.47    77.45     77.45      77.45\n",
            "beta     78.43    78.43     80.39      78.43\n",
            "gamma    76.47    78.43     76.47      76.47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HAHV\",\"lgbm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHLHgabcnysD",
        "outputId": "ffbc0f39-bc42-4d02-ea09-9a47e8132756"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 248, number of negative: 674\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000251 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.268980 -> initscore=-0.999801\n",
            "[LightGBM] [Info] Start training from score -0.999801\n",
            "[LightGBM] [Info] Number of positive: 248, number of negative: 674\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000144 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.268980 -> initscore=-0.999801\n",
            "[LightGBM] [Info] Start training from score -0.999801\n",
            "[LightGBM] [Info] Number of positive: 248, number of negative: 674\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000122 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.268980 -> initscore=-0.999801\n",
            "[LightGBM] [Info] Start training from score -0.999801\n",
            "[LightGBM] [Info] Number of positive: 248, number of negative: 674\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000118 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.268980 -> initscore=-0.999801\n",
            "[LightGBM] [Info] Start training from score -0.999801\n",
            "[LightGBM] [Info] Number of positive: 248, number of negative: 674\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000116 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.268980 -> initscore=-0.999801\n",
            "[LightGBM] [Info] Start training from score -0.999801\n",
            "[LightGBM] [Info] Number of positive: 248, number of negative: 674\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.268980 -> initscore=-0.999801\n",
            "[LightGBM] [Info] Start training from score -0.999801\n",
            "[LightGBM] [Info] Number of positive: 248, number of negative: 674\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000109 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.268980 -> initscore=-0.999801\n",
            "[LightGBM] [Info] Start training from score -0.999801\n",
            "[LightGBM] [Info] Number of positive: 248, number of negative: 674\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000123 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.268980 -> initscore=-0.999801\n",
            "[LightGBM] [Info] Start training from score -0.999801\n",
            "[LightGBM] [Info] Number of positive: 248, number of negative: 674\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000114 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.268980 -> initscore=-0.999801\n",
            "[LightGBM] [Info] Start training from score -0.999801\n",
            "[LightGBM] [Info] Number of positive: 248, number of negative: 674\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.268980 -> initscore=-0.999801\n",
            "[LightGBM] [Info] Start training from score -0.999801\n",
            "[LightGBM] [Info] Number of positive: 248, number of negative: 674\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000111 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.268980 -> initscore=-0.999801\n",
            "[LightGBM] [Info] Start training from score -0.999801\n",
            "[LightGBM] [Info] Number of positive: 248, number of negative: 674\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000109 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.268980 -> initscore=-0.999801\n",
            "[LightGBM] [Info] Start training from score -0.999801\n",
            "[LightGBM] [Info] Number of positive: 248, number of negative: 674\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000126 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.268980 -> initscore=-0.999801\n",
            "[LightGBM] [Info] Start training from score -0.999801\n",
            "[LightGBM] [Info] Number of positive: 248, number of negative: 674\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000140 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.268980 -> initscore=-0.999801\n",
            "[LightGBM] [Info] Start training from score -0.999801\n",
            "[LightGBM] [Info] Number of positive: 248, number of negative: 674\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000071 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.268980 -> initscore=-0.999801\n",
            "[LightGBM] [Info] Start training from score -0.999801\n",
            "[LightGBM] [Info] Number of positive: 248, number of negative: 674\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000110 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.268980 -> initscore=-0.999801\n",
            "[LightGBM] [Info] Start training from score -0.999801\n",
            "       frontal  central  parietal  occipital\n",
            "theta    63.73    64.71     58.82      58.82\n",
            "alpha    68.63    66.67     60.78      63.73\n",
            "beta     63.73    62.75     62.75      63.73\n",
            "gamma    71.57    65.69     68.63      67.65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LAHV\",\"lgbm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7RfoknLn90T",
        "outputId": "dd4a4914-4572-4ea6-c69e-102f6110035b"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 230, number of negative: 692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000110 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249458 -> initscore=-1.101507\n",
            "[LightGBM] [Info] Start training from score -1.101507\n",
            "[LightGBM] [Info] Number of positive: 230, number of negative: 692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249458 -> initscore=-1.101507\n",
            "[LightGBM] [Info] Start training from score -1.101507\n",
            "[LightGBM] [Info] Number of positive: 230, number of negative: 692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000117 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249458 -> initscore=-1.101507\n",
            "[LightGBM] [Info] Start training from score -1.101507\n",
            "[LightGBM] [Info] Number of positive: 230, number of negative: 692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000124 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249458 -> initscore=-1.101507\n",
            "[LightGBM] [Info] Start training from score -1.101507\n",
            "[LightGBM] [Info] Number of positive: 230, number of negative: 692\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000087 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249458 -> initscore=-1.101507\n",
            "[LightGBM] [Info] Start training from score -1.101507\n",
            "[LightGBM] [Info] Number of positive: 230, number of negative: 692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249458 -> initscore=-1.101507\n",
            "[LightGBM] [Info] Start training from score -1.101507\n",
            "[LightGBM] [Info] Number of positive: 230, number of negative: 692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000122 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249458 -> initscore=-1.101507\n",
            "[LightGBM] [Info] Start training from score -1.101507\n",
            "[LightGBM] [Info] Number of positive: 230, number of negative: 692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000121 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249458 -> initscore=-1.101507\n",
            "[LightGBM] [Info] Start training from score -1.101507\n",
            "[LightGBM] [Info] Number of positive: 230, number of negative: 692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000124 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249458 -> initscore=-1.101507\n",
            "[LightGBM] [Info] Start training from score -1.101507\n",
            "[LightGBM] [Info] Number of positive: 230, number of negative: 692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249458 -> initscore=-1.101507\n",
            "[LightGBM] [Info] Start training from score -1.101507\n",
            "[LightGBM] [Info] Number of positive: 230, number of negative: 692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000121 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249458 -> initscore=-1.101507\n",
            "[LightGBM] [Info] Start training from score -1.101507\n",
            "[LightGBM] [Info] Number of positive: 230, number of negative: 692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000120 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249458 -> initscore=-1.101507\n",
            "[LightGBM] [Info] Start training from score -1.101507\n",
            "[LightGBM] [Info] Number of positive: 230, number of negative: 692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000120 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249458 -> initscore=-1.101507\n",
            "[LightGBM] [Info] Start training from score -1.101507\n",
            "[LightGBM] [Info] Number of positive: 230, number of negative: 692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249458 -> initscore=-1.101507\n",
            "[LightGBM] [Info] Start training from score -1.101507\n",
            "[LightGBM] [Info] Number of positive: 230, number of negative: 692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000133 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249458 -> initscore=-1.101507\n",
            "[LightGBM] [Info] Start training from score -1.101507\n",
            "[LightGBM] [Info] Number of positive: 230, number of negative: 692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000108 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249458 -> initscore=-1.101507\n",
            "[LightGBM] [Info] Start training from score -1.101507\n",
            "       frontal  central  parietal  occipital\n",
            "theta    65.69    68.63     64.71      69.61\n",
            "alpha    68.63    72.55     69.61      71.57\n",
            "beta     68.63    66.67     70.59      69.61\n",
            "gamma    68.63    74.51     71.57      70.59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HALV\",\"lgbm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXpblqNyoDsM",
        "outputId": "8167ef44-82c9-4105-b72e-aa39517e3c15"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 210, number of negative: 712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000111 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.227766 -> initscore=-1.220970\n",
            "[LightGBM] [Info] Start training from score -1.220970\n",
            "[LightGBM] [Info] Number of positive: 210, number of negative: 712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000150 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.227766 -> initscore=-1.220970\n",
            "[LightGBM] [Info] Start training from score -1.220970\n",
            "[LightGBM] [Info] Number of positive: 210, number of negative: 712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000108 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.227766 -> initscore=-1.220970\n",
            "[LightGBM] [Info] Start training from score -1.220970\n",
            "[LightGBM] [Info] Number of positive: 210, number of negative: 712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000118 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.227766 -> initscore=-1.220970\n",
            "[LightGBM] [Info] Start training from score -1.220970\n",
            "[LightGBM] [Info] Number of positive: 210, number of negative: 712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000108 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.227766 -> initscore=-1.220970\n",
            "[LightGBM] [Info] Start training from score -1.220970\n",
            "[LightGBM] [Info] Number of positive: 210, number of negative: 712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.227766 -> initscore=-1.220970\n",
            "[LightGBM] [Info] Start training from score -1.220970\n",
            "[LightGBM] [Info] Number of positive: 210, number of negative: 712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000119 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.227766 -> initscore=-1.220970\n",
            "[LightGBM] [Info] Start training from score -1.220970\n",
            "[LightGBM] [Info] Number of positive: 210, number of negative: 712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000109 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.227766 -> initscore=-1.220970\n",
            "[LightGBM] [Info] Start training from score -1.220970\n",
            "[LightGBM] [Info] Number of positive: 210, number of negative: 712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000107 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.227766 -> initscore=-1.220970\n",
            "[LightGBM] [Info] Start training from score -1.220970\n",
            "[LightGBM] [Info] Number of positive: 210, number of negative: 712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000098 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.227766 -> initscore=-1.220970\n",
            "[LightGBM] [Info] Start training from score -1.220970\n",
            "[LightGBM] [Info] Number of positive: 210, number of negative: 712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000119 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.227766 -> initscore=-1.220970\n",
            "[LightGBM] [Info] Start training from score -1.220970\n",
            "[LightGBM] [Info] Number of positive: 210, number of negative: 712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000117 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.227766 -> initscore=-1.220970\n",
            "[LightGBM] [Info] Start training from score -1.220970\n",
            "[LightGBM] [Info] Number of positive: 210, number of negative: 712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.227766 -> initscore=-1.220970\n",
            "[LightGBM] [Info] Start training from score -1.220970\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 210, number of negative: 712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000141 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.227766 -> initscore=-1.220970\n",
            "[LightGBM] [Info] Start training from score -1.220970\n",
            "[LightGBM] [Info] Number of positive: 210, number of negative: 712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000109 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.227766 -> initscore=-1.220970\n",
            "[LightGBM] [Info] Start training from score -1.220970\n",
            "[LightGBM] [Info] Number of positive: 210, number of negative: 712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000108 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.227766 -> initscore=-1.220970\n",
            "[LightGBM] [Info] Start training from score -1.220970\n",
            "       frontal  central  parietal  occipital\n",
            "theta    80.39    78.43     80.39      76.47\n",
            "alpha    81.37    86.27     79.41      73.53\n",
            "beta     77.45    76.47     79.41      80.39\n",
            "gamma    84.31    79.41     83.33      73.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LALV\",\"lgbm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4u-SszMVoFo6",
        "outputId": "3e7ba3bb-6ea2-441d-8024-075a1be62be5"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 234, number of negative: 688\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000118 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.253796 -> initscore=-1.078468\n",
            "[LightGBM] [Info] Start training from score -1.078468\n",
            "[LightGBM] [Info] Number of positive: 234, number of negative: 688\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000134 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.253796 -> initscore=-1.078468\n",
            "[LightGBM] [Info] Start training from score -1.078468\n",
            "[LightGBM] [Info] Number of positive: 234, number of negative: 688\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000110 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.253796 -> initscore=-1.078468\n",
            "[LightGBM] [Info] Start training from score -1.078468\n",
            "[LightGBM] [Info] Number of positive: 234, number of negative: 688\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000110 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.253796 -> initscore=-1.078468\n",
            "[LightGBM] [Info] Start training from score -1.078468\n",
            "[LightGBM] [Info] Number of positive: 234, number of negative: 688\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000108 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.253796 -> initscore=-1.078468\n",
            "[LightGBM] [Info] Start training from score -1.078468\n",
            "[LightGBM] [Info] Number of positive: 234, number of negative: 688\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.253796 -> initscore=-1.078468\n",
            "[LightGBM] [Info] Start training from score -1.078468\n",
            "[LightGBM] [Info] Number of positive: 234, number of negative: 688\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000117 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.253796 -> initscore=-1.078468\n",
            "[LightGBM] [Info] Start training from score -1.078468\n",
            "[LightGBM] [Info] Number of positive: 234, number of negative: 688\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000111 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.253796 -> initscore=-1.078468\n",
            "[LightGBM] [Info] Start training from score -1.078468\n",
            "[LightGBM] [Info] Number of positive: 234, number of negative: 688\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000107 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.253796 -> initscore=-1.078468\n",
            "[LightGBM] [Info] Start training from score -1.078468\n",
            "[LightGBM] [Info] Number of positive: 234, number of negative: 688\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.253796 -> initscore=-1.078468\n",
            "[LightGBM] [Info] Start training from score -1.078468\n",
            "[LightGBM] [Info] Number of positive: 234, number of negative: 688\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000140 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.253796 -> initscore=-1.078468\n",
            "[LightGBM] [Info] Start training from score -1.078468\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 234, number of negative: 688\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000127 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.253796 -> initscore=-1.078468\n",
            "[LightGBM] [Info] Start training from score -1.078468\n",
            "[LightGBM] [Info] Number of positive: 234, number of negative: 688\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000134 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.253796 -> initscore=-1.078468\n",
            "[LightGBM] [Info] Start training from score -1.078468\n",
            "[LightGBM] [Info] Number of positive: 234, number of negative: 688\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000152 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.253796 -> initscore=-1.078468\n",
            "[LightGBM] [Info] Start training from score -1.078468\n",
            "[LightGBM] [Info] Number of positive: 234, number of negative: 688\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000122 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.253796 -> initscore=-1.078468\n",
            "[LightGBM] [Info] Start training from score -1.078468\n",
            "[LightGBM] [Info] Number of positive: 234, number of negative: 688\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000125 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.253796 -> initscore=-1.078468\n",
            "[LightGBM] [Info] Start training from score -1.078468\n",
            "       frontal  central  parietal  occipital\n",
            "theta    74.51    74.51     72.55      67.65\n",
            "alpha    76.47    75.49     79.41      75.49\n",
            "beta     73.53    77.45     73.53      74.51\n",
            "gamma    75.49    77.45     73.53      71.57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HAHV\",\"gpc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJGDn8dVoIS0",
        "outputId": "393d8af3-ef74-4c1f-81c0-94f80f77784b"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    67.65    67.65     67.65      67.65\n",
            "alpha    67.65    67.65     67.65      67.65\n",
            "beta     67.65    67.65     67.65      67.65\n",
            "gamma    67.65    67.65     67.65      65.69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LAHV\",\"gpc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peDp-nMaoPit",
        "outputId": "ffa28371-3b8b-4138-95cc-c2f9d19e0c35"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    71.57    71.57     71.57      72.55\n",
            "alpha    71.57    71.57     71.57      72.55\n",
            "beta     71.57    71.57     71.57      72.55\n",
            "gamma    71.57    71.57     71.57      71.57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HALV\",\"gpc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35McLer6oSSg",
        "outputId": "2e893a9c-d6ef-429c-f795-efad621b4b92"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    81.37    81.37     81.37      81.37\n",
            "alpha    81.37    81.37     81.37      81.37\n",
            "beta     81.37    81.37     81.37      82.35\n",
            "gamma    81.37    80.39     81.37      81.37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LALV\",\"gpc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWMhm_XAoVDl",
        "outputId": "d18a5d63-e307-4f26-f0f0-6e7fca15efb1"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    78.43    79.41     79.41      78.43\n",
            "alpha    78.43    79.41     79.41      78.43\n",
            "beta     79.41    79.41     79.41      78.43\n",
            "gamma    79.41    79.41     78.43      77.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HAHV\",\"per\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo4ffCb7oZ2x",
        "outputId": "5c9249fb-5215-43e2-9fac-d38cf011cdc2"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    55.88    57.84     59.80      59.80\n",
            "alpha    40.20    57.84     56.86      48.04\n",
            "beta     62.75    53.92     50.00      62.75\n",
            "gamma    58.82    57.84     39.22      61.76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LAHV\",\"per\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfEA3KWLoc9e",
        "outputId": "fe093bb8-b478-4710-fe92-c0a79e594379"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    65.69    38.24     56.86      31.37\n",
            "alpha    36.27    38.24     57.84      49.02\n",
            "beta     64.71    43.14     58.82      32.35\n",
            "gamma    63.73    37.25     44.12      71.57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HALV\",\"per\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5BnwXVfogUL",
        "outputId": "6c29536d-8deb-4292-dbdf-ab778ef77132"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    79.41    73.53     70.59      76.47\n",
            "alpha    74.51    78.43     74.51      53.92\n",
            "beta     81.37    51.96     68.63      74.51\n",
            "gamma    81.37    81.37     70.59      78.43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LALV\",\"per\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXjBfPXJoorP",
        "outputId": "fcce3313-fc9a-4013-e20c-e9443b18fbbf"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    61.76    53.92     70.59      42.16\n",
            "alpha    67.65    70.59     72.55      36.27\n",
            "beta     47.06    68.63     56.86      69.61\n",
            "gamma    66.67    53.92     31.37      62.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HAHV\",\"cb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLC_cx8Jorcu",
        "outputId": "350b1d36-2e84-44aa-d66c-e525c523cf57"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    62.75    66.67     58.82      56.86\n",
            "alpha    65.69    67.65     63.73      62.75\n",
            "beta     66.67    65.69     61.76      59.80\n",
            "gamma    64.71    60.78     71.57      71.57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LAHV\",\"cb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLm53vGeowND",
        "outputId": "b8e9bd86-f5df-44f7-c087-ba5e98665d48"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    72.55    70.59     65.69      68.63\n",
            "alpha    66.67    72.55     68.63      69.61\n",
            "beta     64.71    69.61     64.71      68.63\n",
            "gamma    65.69    77.45     68.63      64.71\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HALV\",\"cb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poVbrGLKozIC",
        "outputId": "44704588-f1e3-493f-aa09-6cc2eb0bd594"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    79.41    78.43     77.45      77.45\n",
            "alpha    78.43    79.41     76.47      74.51\n",
            "beta     82.35    74.51     80.39      78.43\n",
            "gamma    78.43    80.39     83.33      77.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LALV\",\"cb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDs9Xl3_o173",
        "outputId": "77ed37c3-2950-43c9-8b46-4448fe10a518"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    70.59    71.57     72.55      68.63\n",
            "alpha    73.53    76.47     80.39      80.39\n",
            "beta     72.55    75.49     75.49      73.53\n",
            "gamma    71.57    73.53     74.51      70.59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HAHV\",\"cnn\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BJq0tCp5h3c",
        "outputId": "b3cc8bf9-d527-4246-ba7e-01819d364793"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "32/32 [==============================] - 8s 19ms/step - loss: 0.7781 - accuracy: 0.6445 - val_loss: 0.7712 - val_accuracy: 0.6016\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.7150 - accuracy: 0.6865 - val_loss: 0.6334 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6678 - accuracy: 0.7012 - val_loss: 0.6197 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6607 - accuracy: 0.6963 - val_loss: 0.6138 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6410 - accuracy: 0.7100 - val_loss: 0.6417 - val_accuracy: 0.6641\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6506 - accuracy: 0.7129 - val_loss: 0.6195 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6481 - accuracy: 0.7012 - val_loss: 0.6100 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6496 - accuracy: 0.7041 - val_loss: 0.6104 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6524 - accuracy: 0.7002 - val_loss: 0.6345 - val_accuracy: 0.6562\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6169 - accuracy: 0.7109 - val_loss: 0.6069 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6206 - accuracy: 0.7197 - val_loss: 0.6060 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6298 - accuracy: 0.7021 - val_loss: 0.6111 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6152 - accuracy: 0.7158 - val_loss: 0.6140 - val_accuracy: 0.6953\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6090 - accuracy: 0.7148 - val_loss: 0.6056 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6300 - accuracy: 0.7070 - val_loss: 0.6130 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6151 - accuracy: 0.7275 - val_loss: 0.6319 - val_accuracy: 0.6641\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6053 - accuracy: 0.7178 - val_loss: 0.6249 - val_accuracy: 0.6719\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6163 - accuracy: 0.7119 - val_loss: 0.6052 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6199 - accuracy: 0.7178 - val_loss: 0.6139 - val_accuracy: 0.6953\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6119 - accuracy: 0.7178 - val_loss: 0.6009 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6009 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 3s 17ms/step - loss: 0.7164 - accuracy: 0.6582 - val_loss: 0.7223 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.6590 - accuracy: 0.7051 - val_loss: 0.6569 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.6336 - accuracy: 0.6895 - val_loss: 0.6584 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6471 - accuracy: 0.6973 - val_loss: 0.6747 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.6294 - accuracy: 0.7031 - val_loss: 0.6428 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6109 - accuracy: 0.7168 - val_loss: 0.6535 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6265 - accuracy: 0.7021 - val_loss: 0.6251 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6145 - accuracy: 0.7217 - val_loss: 0.6220 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6018 - accuracy: 0.7227 - val_loss: 0.6186 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6308 - accuracy: 0.7080 - val_loss: 0.6160 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6088 - accuracy: 0.7139 - val_loss: 0.6162 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.6156 - accuracy: 0.7246 - val_loss: 0.6261 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6014 - accuracy: 0.7217 - val_loss: 0.6263 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.6096 - accuracy: 0.7109 - val_loss: 0.6305 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.6084 - accuracy: 0.7207 - val_loss: 0.6237 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.6026 - accuracy: 0.7236 - val_loss: 0.6282 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.6051 - accuracy: 0.7188 - val_loss: 0.6213 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.6160 - accuracy: 0.7100 - val_loss: 0.6185 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.6014 - accuracy: 0.7266 - val_loss: 0.6186 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.6038 - accuracy: 0.7207 - val_loss: 0.6202 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6202 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 3s 15ms/step - loss: 0.7907 - accuracy: 0.6328 - val_loss: 0.6576 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6708 - accuracy: 0.6807 - val_loss: 0.6219 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6646 - accuracy: 0.6895 - val_loss: 0.6125 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6563 - accuracy: 0.6914 - val_loss: 0.6055 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6260 - accuracy: 0.6982 - val_loss: 0.6034 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6409 - accuracy: 0.7031 - val_loss: 0.6040 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.6301 - accuracy: 0.7090 - val_loss: 0.6045 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6427 - accuracy: 0.7002 - val_loss: 0.6137 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6229 - accuracy: 0.7178 - val_loss: 0.6089 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6140 - accuracy: 0.7119 - val_loss: 0.6087 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6182 - accuracy: 0.7100 - val_loss: 0.6085 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6048 - accuracy: 0.7227 - val_loss: 0.6059 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6072 - accuracy: 0.7148 - val_loss: 0.6084 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6037 - accuracy: 0.7119 - val_loss: 0.6081 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6121 - accuracy: 0.7168 - val_loss: 0.6175 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6189 - accuracy: 0.7158 - val_loss: 0.6157 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6084 - accuracy: 0.7148 - val_loss: 0.6154 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.6065 - accuracy: 0.7266 - val_loss: 0.6151 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5942 - accuracy: 0.7227 - val_loss: 0.6157 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6031 - accuracy: 0.7227 - val_loss: 0.6169 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6169 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 15ms/step - loss: 0.8001 - accuracy: 0.6406 - val_loss: 0.7100 - val_accuracy: 0.6289\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.6926 - accuracy: 0.6953 - val_loss: 0.8001 - val_accuracy: 0.6055\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.6846 - accuracy: 0.6904 - val_loss: 0.7417 - val_accuracy: 0.6055\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.6434 - accuracy: 0.7070 - val_loss: 0.6272 - val_accuracy: 0.6797\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6627 - accuracy: 0.7041 - val_loss: 0.6136 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6545 - accuracy: 0.6943 - val_loss: 0.6439 - val_accuracy: 0.6758\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6391 - accuracy: 0.7178 - val_loss: 0.6076 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6387 - accuracy: 0.7119 - val_loss: 0.6117 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6283 - accuracy: 0.7109 - val_loss: 0.6110 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6224 - accuracy: 0.7178 - val_loss: 0.6097 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6181 - accuracy: 0.7197 - val_loss: 0.6275 - val_accuracy: 0.6797\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6173 - accuracy: 0.7070 - val_loss: 0.6059 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6143 - accuracy: 0.7207 - val_loss: 0.6080 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.6299 - accuracy: 0.7139 - val_loss: 0.6159 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.6181 - accuracy: 0.7188 - val_loss: 0.6034 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.6042 - accuracy: 0.7217 - val_loss: 0.6125 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.6116 - accuracy: 0.7217 - val_loss: 0.6063 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.6007 - accuracy: 0.7236 - val_loss: 0.6041 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.6139 - accuracy: 0.7197 - val_loss: 0.6029 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.6049 - accuracy: 0.7188 - val_loss: 0.6098 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6098 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 3s 14ms/step - loss: 0.8618 - accuracy: 0.5928 - val_loss: 0.6503 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.7049 - accuracy: 0.6621 - val_loss: 0.6271 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6778 - accuracy: 0.6787 - val_loss: 0.6225 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6881 - accuracy: 0.6826 - val_loss: 0.6229 - val_accuracy: 0.6875\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6634 - accuracy: 0.6953 - val_loss: 0.6044 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6509 - accuracy: 0.7031 - val_loss: 0.6250 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6297 - accuracy: 0.7168 - val_loss: 0.6052 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6192 - accuracy: 0.7129 - val_loss: 0.6120 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6251 - accuracy: 0.7168 - val_loss: 0.6127 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6181 - accuracy: 0.7168 - val_loss: 0.6048 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6329 - accuracy: 0.7197 - val_loss: 0.6037 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6143 - accuracy: 0.7100 - val_loss: 0.6097 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6152 - accuracy: 0.7129 - val_loss: 0.6065 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6163 - accuracy: 0.7148 - val_loss: 0.6038 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6157 - accuracy: 0.7188 - val_loss: 0.6030 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6175 - accuracy: 0.7197 - val_loss: 0.6023 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6183 - accuracy: 0.7188 - val_loss: 0.6008 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6044 - accuracy: 0.7236 - val_loss: 0.6003 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6129 - accuracy: 0.7227 - val_loss: 0.6001 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5979 - accuracy: 0.7227 - val_loss: 0.6067 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6067 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 14ms/step - loss: 0.7529 - accuracy: 0.6631 - val_loss: 0.6606 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6987 - accuracy: 0.6680 - val_loss: 0.6965 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6754 - accuracy: 0.7031 - val_loss: 0.6344 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6530 - accuracy: 0.6826 - val_loss: 0.6237 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.6614 - accuracy: 0.6992 - val_loss: 0.6191 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6642 - accuracy: 0.6973 - val_loss: 0.6301 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6454 - accuracy: 0.7031 - val_loss: 0.6304 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6454 - accuracy: 0.7012 - val_loss: 0.6286 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6232 - accuracy: 0.7148 - val_loss: 0.6156 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6218 - accuracy: 0.7148 - val_loss: 0.6241 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6195 - accuracy: 0.7080 - val_loss: 0.6266 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6356 - accuracy: 0.7158 - val_loss: 0.6252 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6188 - accuracy: 0.7109 - val_loss: 0.6183 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6265 - accuracy: 0.7129 - val_loss: 0.6248 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6149 - accuracy: 0.7178 - val_loss: 0.6252 - val_accuracy: 0.7031\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.6179 - accuracy: 0.7100 - val_loss: 0.6154 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6087 - accuracy: 0.7197 - val_loss: 0.6158 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.6080 - accuracy: 0.7217 - val_loss: 0.6200 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.6070 - accuracy: 0.7188 - val_loss: 0.6144 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.6055 - accuracy: 0.7197 - val_loss: 0.6195 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6195 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 3s 21ms/step - loss: 0.7577 - accuracy: 0.6338 - val_loss: 0.7070 - val_accuracy: 0.6094\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.6902 - accuracy: 0.6768 - val_loss: 0.6687 - val_accuracy: 0.6289\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.6476 - accuracy: 0.6982 - val_loss: 0.6202 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6597 - accuracy: 0.6914 - val_loss: 0.6195 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6474 - accuracy: 0.7051 - val_loss: 0.6160 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6511 - accuracy: 0.7012 - val_loss: 0.6086 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6408 - accuracy: 0.7129 - val_loss: 0.6245 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.6412 - accuracy: 0.6904 - val_loss: 0.6092 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6241 - accuracy: 0.7041 - val_loss: 0.6174 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6269 - accuracy: 0.7100 - val_loss: 0.6117 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6282 - accuracy: 0.7207 - val_loss: 0.6214 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6221 - accuracy: 0.7139 - val_loss: 0.6139 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6123 - accuracy: 0.7148 - val_loss: 0.6197 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6251 - accuracy: 0.7070 - val_loss: 0.6126 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6046 - accuracy: 0.7178 - val_loss: 0.6127 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6089 - accuracy: 0.7139 - val_loss: 0.6283 - val_accuracy: 0.6719\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6018 - accuracy: 0.7148 - val_loss: 0.6105 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6072 - accuracy: 0.7227 - val_loss: 0.6092 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6038 - accuracy: 0.7119 - val_loss: 0.6117 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6095 - accuracy: 0.7207 - val_loss: 0.6095 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6095 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 16ms/step - loss: 0.7461 - accuracy: 0.6406 - val_loss: 0.6292 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.7069 - accuracy: 0.6641 - val_loss: 0.6161 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.6735 - accuracy: 0.6924 - val_loss: 0.6127 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6432 - accuracy: 0.7061 - val_loss: 0.6018 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6321 - accuracy: 0.7051 - val_loss: 0.6183 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6567 - accuracy: 0.7100 - val_loss: 0.6036 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6519 - accuracy: 0.7021 - val_loss: 0.6013 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6242 - accuracy: 0.7188 - val_loss: 0.6077 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6237 - accuracy: 0.7012 - val_loss: 0.6042 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6141 - accuracy: 0.7178 - val_loss: 0.6049 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.6149 - accuracy: 0.7178 - val_loss: 0.6058 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.6200 - accuracy: 0.7109 - val_loss: 0.6090 - val_accuracy: 0.6953\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.6183 - accuracy: 0.7168 - val_loss: 0.6013 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.6132 - accuracy: 0.7188 - val_loss: 0.5993 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6017 - accuracy: 0.7188 - val_loss: 0.6164 - val_accuracy: 0.6953\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6105 - accuracy: 0.7188 - val_loss: 0.6004 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6130 - accuracy: 0.7158 - val_loss: 0.6000 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 1s 31ms/step - loss: 0.6065 - accuracy: 0.7197 - val_loss: 0.6144 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.6171 - accuracy: 0.7188 - val_loss: 0.6210 - val_accuracy: 0.6836\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.5965 - accuracy: 0.7158 - val_loss: 0.6047 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6047 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 5s 23ms/step - loss: 0.6925 - accuracy: 0.6787 - val_loss: 0.9093 - val_accuracy: 0.5820\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.6590 - accuracy: 0.6895 - val_loss: 0.6817 - val_accuracy: 0.6445\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.6373 - accuracy: 0.7188 - val_loss: 0.6292 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.6388 - accuracy: 0.7070 - val_loss: 0.6444 - val_accuracy: 0.6719\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.6563 - accuracy: 0.7070 - val_loss: 0.6881 - val_accuracy: 0.6602\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.6032 - accuracy: 0.7188 - val_loss: 0.6369 - val_accuracy: 0.6797\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.6262 - accuracy: 0.7109 - val_loss: 0.6223 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.6151 - accuracy: 0.7197 - val_loss: 0.6168 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.6278 - accuracy: 0.7207 - val_loss: 0.6097 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.6145 - accuracy: 0.7197 - val_loss: 0.6144 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.6056 - accuracy: 0.7207 - val_loss: 0.6110 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.6150 - accuracy: 0.7158 - val_loss: 0.6224 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.6153 - accuracy: 0.7148 - val_loss: 0.6145 - val_accuracy: 0.6836\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5962 - accuracy: 0.7217 - val_loss: 0.6136 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.6118 - accuracy: 0.7158 - val_loss: 0.6120 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.6203 - accuracy: 0.7158 - val_loss: 0.6183 - val_accuracy: 0.6797\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6034 - accuracy: 0.7197 - val_loss: 0.6079 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5969 - accuracy: 0.7227 - val_loss: 0.6092 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5982 - accuracy: 0.7236 - val_loss: 0.6158 - val_accuracy: 0.6836\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6009 - accuracy: 0.7227 - val_loss: 0.6123 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6123 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 3s 14ms/step - loss: 0.7521 - accuracy: 0.6406 - val_loss: 0.6476 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6574 - accuracy: 0.6963 - val_loss: 0.6892 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6582 - accuracy: 0.6914 - val_loss: 0.6457 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6516 - accuracy: 0.7041 - val_loss: 0.6414 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6436 - accuracy: 0.7109 - val_loss: 0.6477 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6319 - accuracy: 0.7119 - val_loss: 0.6260 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6390 - accuracy: 0.7100 - val_loss: 0.6203 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6265 - accuracy: 0.7119 - val_loss: 0.6203 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.6270 - accuracy: 0.7148 - val_loss: 0.6129 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.6280 - accuracy: 0.7148 - val_loss: 0.6157 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.6201 - accuracy: 0.7158 - val_loss: 0.6147 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.6031 - accuracy: 0.7236 - val_loss: 0.6276 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.6201 - accuracy: 0.7207 - val_loss: 0.6191 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6222 - accuracy: 0.7051 - val_loss: 0.6199 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5958 - accuracy: 0.7256 - val_loss: 0.6163 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6199 - accuracy: 0.7158 - val_loss: 0.6166 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5952 - accuracy: 0.7227 - val_loss: 0.6140 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5972 - accuracy: 0.7236 - val_loss: 0.6155 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.6140 - accuracy: 0.7178 - val_loss: 0.6164 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5920 - accuracy: 0.7266 - val_loss: 0.6156 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6156 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 14ms/step - loss: 0.8751 - accuracy: 0.5723 - val_loss: 0.6676 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6781 - accuracy: 0.6729 - val_loss: 0.6363 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6483 - accuracy: 0.6875 - val_loss: 0.6204 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6593 - accuracy: 0.6865 - val_loss: 0.6113 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6316 - accuracy: 0.7051 - val_loss: 0.6152 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6190 - accuracy: 0.7080 - val_loss: 0.6187 - val_accuracy: 0.6914\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6238 - accuracy: 0.7090 - val_loss: 0.6087 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6131 - accuracy: 0.7197 - val_loss: 0.6070 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6224 - accuracy: 0.7129 - val_loss: 0.6127 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.6382 - accuracy: 0.7002 - val_loss: 0.6141 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.6316 - accuracy: 0.7139 - val_loss: 0.6131 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.6130 - accuracy: 0.7080 - val_loss: 0.6059 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.6240 - accuracy: 0.7158 - val_loss: 0.6098 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.6042 - accuracy: 0.7178 - val_loss: 0.6127 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.6131 - accuracy: 0.7139 - val_loss: 0.6120 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.6005 - accuracy: 0.7197 - val_loss: 0.6257 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.6016 - accuracy: 0.7168 - val_loss: 0.6176 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.6046 - accuracy: 0.7236 - val_loss: 0.6147 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5964 - accuracy: 0.7266 - val_loss: 0.6110 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.6030 - accuracy: 0.7148 - val_loss: 0.6156 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6156 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 3s 17ms/step - loss: 0.7342 - accuracy: 0.6660 - val_loss: 0.6456 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6840 - accuracy: 0.7002 - val_loss: 0.6395 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6782 - accuracy: 0.6875 - val_loss: 0.6289 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.7049 - accuracy: 0.6982 - val_loss: 0.6205 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6668 - accuracy: 0.7148 - val_loss: 0.6251 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6320 - accuracy: 0.6973 - val_loss: 0.6204 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.6348 - accuracy: 0.7080 - val_loss: 0.6191 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 1s 25ms/step - loss: 0.6336 - accuracy: 0.7021 - val_loss: 0.6191 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.6536 - accuracy: 0.7119 - val_loss: 0.6338 - val_accuracy: 0.6836\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6339 - accuracy: 0.7119 - val_loss: 0.6158 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6096 - accuracy: 0.7217 - val_loss: 0.6154 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6213 - accuracy: 0.7109 - val_loss: 0.6153 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6184 - accuracy: 0.7178 - val_loss: 0.6186 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6278 - accuracy: 0.7109 - val_loss: 0.6090 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6147 - accuracy: 0.7178 - val_loss: 0.6082 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6037 - accuracy: 0.7148 - val_loss: 0.6099 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5997 - accuracy: 0.7188 - val_loss: 0.6066 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5990 - accuracy: 0.7197 - val_loss: 0.6122 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.6004 - accuracy: 0.7188 - val_loss: 0.6129 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.6078 - accuracy: 0.7158 - val_loss: 0.6108 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6108 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 3s 21ms/step - loss: 0.7303 - accuracy: 0.6562 - val_loss: 0.6545 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.6705 - accuracy: 0.6934 - val_loss: 0.6518 - val_accuracy: 0.6836\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.6321 - accuracy: 0.7051 - val_loss: 0.6367 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.6449 - accuracy: 0.7129 - val_loss: 0.6272 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6300 - accuracy: 0.7041 - val_loss: 0.6249 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6358 - accuracy: 0.7168 - val_loss: 0.6294 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6177 - accuracy: 0.7129 - val_loss: 0.6283 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6324 - accuracy: 0.7148 - val_loss: 0.6272 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6124 - accuracy: 0.7129 - val_loss: 0.6168 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6074 - accuracy: 0.7139 - val_loss: 0.6187 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6159 - accuracy: 0.7168 - val_loss: 0.6218 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6106 - accuracy: 0.7197 - val_loss: 0.6201 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6047 - accuracy: 0.7217 - val_loss: 0.6201 - val_accuracy: 0.6836\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6154 - accuracy: 0.7139 - val_loss: 0.6136 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5931 - accuracy: 0.7207 - val_loss: 0.6179 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6096 - accuracy: 0.7188 - val_loss: 0.6175 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6091 - accuracy: 0.7178 - val_loss: 0.6140 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6057 - accuracy: 0.7227 - val_loss: 0.6204 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6025 - accuracy: 0.7197 - val_loss: 0.6170 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5907 - accuracy: 0.7246 - val_loss: 0.6147 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6147 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 14ms/step - loss: 0.7637 - accuracy: 0.6729 - val_loss: 0.8195 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6815 - accuracy: 0.7002 - val_loss: 0.6815 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6497 - accuracy: 0.7129 - val_loss: 0.6490 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6439 - accuracy: 0.7002 - val_loss: 0.6200 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6468 - accuracy: 0.7031 - val_loss: 0.6531 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6499 - accuracy: 0.7070 - val_loss: 0.6338 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6347 - accuracy: 0.7197 - val_loss: 0.6178 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.6131 - accuracy: 0.7100 - val_loss: 0.6173 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.6259 - accuracy: 0.7031 - val_loss: 0.6182 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.6282 - accuracy: 0.7246 - val_loss: 0.6422 - val_accuracy: 0.6602\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.6213 - accuracy: 0.7051 - val_loss: 0.6216 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.6271 - accuracy: 0.7070 - val_loss: 0.6148 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.6104 - accuracy: 0.7197 - val_loss: 0.6120 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.6299 - accuracy: 0.7207 - val_loss: 0.6128 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.6253 - accuracy: 0.7139 - val_loss: 0.6146 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.6133 - accuracy: 0.7158 - val_loss: 0.6156 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.6051 - accuracy: 0.7148 - val_loss: 0.6141 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.6006 - accuracy: 0.7217 - val_loss: 0.6152 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.6038 - accuracy: 0.7256 - val_loss: 0.6216 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.6085 - accuracy: 0.7168 - val_loss: 0.6165 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6165 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 5s 23ms/step - loss: 0.7304 - accuracy: 0.6738 - val_loss: 0.6773 - val_accuracy: 0.6562\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.6998 - accuracy: 0.6719 - val_loss: 0.6399 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.6495 - accuracy: 0.7207 - val_loss: 0.6309 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.6403 - accuracy: 0.6963 - val_loss: 0.6178 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.6285 - accuracy: 0.7109 - val_loss: 0.6189 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.6242 - accuracy: 0.6992 - val_loss: 0.6117 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.6125 - accuracy: 0.7168 - val_loss: 0.6212 - val_accuracy: 0.6719\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.6287 - accuracy: 0.7021 - val_loss: 0.6108 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.6163 - accuracy: 0.7070 - val_loss: 0.6100 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.6112 - accuracy: 0.7158 - val_loss: 0.6076 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.6120 - accuracy: 0.7100 - val_loss: 0.6044 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.6139 - accuracy: 0.7158 - val_loss: 0.6066 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.5996 - accuracy: 0.7207 - val_loss: 0.6144 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.6132 - accuracy: 0.7178 - val_loss: 0.6090 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.6171 - accuracy: 0.7148 - val_loss: 0.6092 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.6106 - accuracy: 0.7266 - val_loss: 0.6099 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.5980 - accuracy: 0.7188 - val_loss: 0.6150 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.6116 - accuracy: 0.7236 - val_loss: 0.6130 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.6046 - accuracy: 0.7236 - val_loss: 0.6098 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.6009 - accuracy: 0.7256 - val_loss: 0.6124 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6124 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 4s 22ms/step - loss: 0.7371 - accuracy: 0.6465 - val_loss: 0.6399 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.6587 - accuracy: 0.6748 - val_loss: 0.6346 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.6486 - accuracy: 0.7139 - val_loss: 0.6316 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.6250 - accuracy: 0.7119 - val_loss: 0.6370 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.6409 - accuracy: 0.7012 - val_loss: 0.6362 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.6174 - accuracy: 0.7109 - val_loss: 0.6236 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.6134 - accuracy: 0.7129 - val_loss: 0.6191 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.6197 - accuracy: 0.7109 - val_loss: 0.6176 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 1s 22ms/step - loss: 0.6109 - accuracy: 0.7197 - val_loss: 0.6259 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.6016 - accuracy: 0.7188 - val_loss: 0.6275 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6060 - accuracy: 0.7148 - val_loss: 0.6260 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6130 - accuracy: 0.7090 - val_loss: 0.6208 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.6056 - accuracy: 0.7207 - val_loss: 0.6192 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6013 - accuracy: 0.7227 - val_loss: 0.6245 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6204 - accuracy: 0.7090 - val_loss: 0.6212 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6051 - accuracy: 0.7207 - val_loss: 0.6183 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5937 - accuracy: 0.7266 - val_loss: 0.6185 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.6035 - accuracy: 0.7188 - val_loss: 0.6215 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5830 - accuracy: 0.7236 - val_loss: 0.6281 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5955 - accuracy: 0.7197 - val_loss: 0.6239 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6239 - accuracy: 0.6992\n",
            "        frontal   central  parietal  occipital\n",
            "theta  0.699219  0.699219  0.699219   0.699219\n",
            "alpha  0.699219  0.699219  0.699219   0.699219\n",
            "beta   0.699219  0.699219  0.699219   0.699219\n",
            "gamma  0.699219  0.699219  0.699219   0.699219\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LAHV\",\"cnn\")"
      ],
      "metadata": {
        "id": "uEcNSdJ25tkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HALV\",\"cnn\")"
      ],
      "metadata": {
        "id": "G3f2GJMB5zSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LALV\",\"cnn\")"
      ],
      "metadata": {
        "id": "GdsHvSdZ53Cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HAHV\",\"ann\")"
      ],
      "metadata": {
        "id": "G0VmjNVR5_4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LAHV\",\"ann\")"
      ],
      "metadata": {
        "id": "yfDJMmfe6EIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HALV\",\"ann\")"
      ],
      "metadata": {
        "id": "joNsxCym6HBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LALV\",\"ann\")"
      ],
      "metadata": {
        "id": "u_AeFSMS6LMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HAHV\",\"lstm\")"
      ],
      "metadata": {
        "id": "UnnNa1K76OJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LAHV\",\"lstm\")"
      ],
      "metadata": {
        "id": "6EqqV3s_6Q4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HALV\",\"lstm\")"
      ],
      "metadata": {
        "id": "NVmj0QBE6UC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LALV\",\"lstm\")"
      ],
      "metadata": {
        "id": "eOm0SD0q6Vkf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}